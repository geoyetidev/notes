# Goal
The goal of these notes is to gain a better understanding of Large Language Model (LLMs) benchmarking and how the community is grappling with issues of training data sets and their effect on analytic purpose. A key question is,  how do we quantitatively and qualitatively understand how an underlying dataset effects **bias** in the tasks we ask LLMs to perform. 

# [[Annotated Bibliography]]
An opinionated assessment of the underlying resources we've currently read and tried to understand. 

# [[Checklist Notes]]
Notes on how to assess models, corpora of text, and organizations for "readiness" to adopt LLM based technologies based on concepts of risk management and information literacy.

# [[Reading List]]
This page manages the current state of captured documents with respect to what has been read