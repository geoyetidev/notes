<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[LLMs]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib/media/favicon.png</url><title>LLMs</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Sun, 03 Nov 2024 21:33:44 GMT</lastBuildDate><atom:link href="lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Sun, 03 Nov 2024 21:33:29 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[Alec Radford]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Alec Radford.html</link><guid isPermaLink="false">Authors/Alec Radford.md</guid><pubDate>Sat, 02 Nov 2024 21:22:00 GMT</pubDate></item><item><title><![CDATA[Alethea Power]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Alethea Power.html</link><guid isPermaLink="false">Authors/Alethea Power.md</guid><pubDate>Sat, 02 Nov 2024 21:21:04 GMT</pubDate></item><item><title><![CDATA[Alex Nichol]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Alex Nichol.html</link><guid isPermaLink="false">Authors/Alex Nichol.md</guid><pubDate>Sat, 02 Nov 2024 21:21:21 GMT</pubDate></item><item><title><![CDATA[Alex Paino]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Alex Paino.html</link><guid isPermaLink="false">Authors/Alex Paino.md</guid><pubDate>Sat, 02 Nov 2024 21:21:23 GMT</pubDate></item><item><title><![CDATA[Alex Ray]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Alex Ray.html</link><guid isPermaLink="false">Authors/Alex Ray.md</guid><pubDate>Sat, 02 Nov 2024 21:20:37 GMT</pubDate></item><item><title><![CDATA[Alex Wang]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Alex Wang.html</link><guid isPermaLink="false">Authors/Alex Wang.md</guid><pubDate>Sat, 02 Nov 2024 21:00:11 GMT</pubDate></item><item><title><![CDATA[Ali Farhadi]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Ali Farhadi.html</link><guid isPermaLink="false">Authors/Ali Farhadi.md</guid><pubDate>Sat, 02 Nov 2024 19:38:01 GMT</pubDate></item><item><title><![CDATA[Amanpreet Singh]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Amanpreet Singh.html</link><guid isPermaLink="false">Authors/Amanpreet Singh.md</guid><pubDate>Sat, 02 Nov 2024 21:00:17 GMT</pubDate></item><item><title><![CDATA[Anastasios Nikolas Angelopoulos]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Anastasios Nikolas Angelopoulos.html</link><guid isPermaLink="false">Authors/Anastasios Nikolas Angelopoulos.md</guid><pubDate>Sat, 02 Nov 2024 21:37:56 GMT</pubDate></item><item><title><![CDATA[Andrew N. Carr]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Andrew N. Carr.html</link><guid isPermaLink="false">Authors/Andrew N. Carr.md</guid><pubDate>Sat, 02 Nov 2024 21:21:39 GMT</pubDate></item><item><title><![CDATA[Andy Zou]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Andy Zou.html</link><guid isPermaLink="false">Authors/Andy Zou.md</guid><pubDate>Sat, 02 Nov 2024 20:13:41 GMT</pubDate></item><item><title><![CDATA[Ari Holtzman]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Ari Holtzman.html</link><guid isPermaLink="false">Authors/Ari Holtzman.md</guid><pubDate>Sat, 02 Nov 2024 19:37:42 GMT</pubDate></item><item><title><![CDATA[Ariel Herbert-Voss]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Ariel Herbert-Voss.html</link><guid isPermaLink="false">Authors/Ariel Herbert-Voss.md</guid><pubDate>Sat, 02 Nov 2024 21:21:17 GMT</pubDate></item><item><title><![CDATA[Ashish Sabharwal]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Ashish Sabharwal.html</link><guid isPermaLink="false">Authors/Ashish Sabharwal.md</guid><pubDate>Sat, 02 Nov 2024 19:07:29 GMT</pubDate></item><item><title><![CDATA[Augustus Odena]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Augustus Odena.html</link><guid isPermaLink="false">Authors/Augustus Odena.md</guid><pubDate>Sat, 02 Nov 2024 21:43:15 GMT</pubDate></item><item><title><![CDATA[Banghua Zhu]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Banghua Zhu.html</link><guid isPermaLink="false">Authors/Banghua Zhu.md</guid><pubDate>Sat, 02 Nov 2024 21:38:01 GMT</pubDate></item><item><title><![CDATA[Bob McGrew]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Bob McGrew.html</link><guid isPermaLink="false">Authors/Bob McGrew.md</guid><pubDate>Sat, 02 Nov 2024 21:22:15 GMT</pubDate></item><item><title><![CDATA[Brooke Chan]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Brooke Chan.html</link><guid isPermaLink="false">Authors/Brooke Chan.md</guid><pubDate>Sat, 02 Nov 2024 21:20:57 GMT</pubDate></item><item><title><![CDATA[Carissa Schoenick]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Carissa Schoenick.html</link><guid isPermaLink="false">Authors/Carissa Schoenick.md</guid><pubDate>Sat, 02 Nov 2024 19:07:36 GMT</pubDate></item><item><title><![CDATA[Carrie Cai]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Carrie Cai.html</link><guid isPermaLink="false">Authors/Carrie Cai.md</guid><pubDate>Sat, 02 Nov 2024 21:43:27 GMT</pubDate></item><item><title><![CDATA[Christopher Hesse]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Christopher Hesse.html</link><guid isPermaLink="false">Authors/Christopher Hesse.md</guid><pubDate>Sat, 02 Nov 2024 20:50:48 GMT</pubDate></item><item><title><![CDATA[Christopher Manning]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Christopher Manning.html</link><guid isPermaLink="false">Authors/Christopher Manning.md</guid><pubDate>Sun, 03 Nov 2024 20:23:42 GMT</pubDate></item><item><title><![CDATA[Clemens Winter]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Clemens Winter.html</link><guid isPermaLink="false">Authors/Clemens Winter.md</guid><pubDate>Sat, 02 Nov 2024 21:21:06 GMT</pubDate></item><item><title><![CDATA[Collin Burns]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Collin Burns.html</link><guid isPermaLink="false">Authors/Collin Burns.md</guid><pubDate>Sat, 02 Nov 2024 20:13:29 GMT</pubDate></item><item><title><![CDATA[Dacheng Li]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Dacheng Li.html</link><guid isPermaLink="false">Authors/Dacheng Li.md</guid><pubDate>Sat, 02 Nov 2024 21:34:09 GMT</pubDate></item><item><title><![CDATA[Dan Hendrycks]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Dan Hendrycks.html</link><guid isPermaLink="false">Authors/Dan Hendrycks.md</guid><pubDate>Sat, 02 Nov 2024 20:13:12 GMT</pubDate></item><item><title><![CDATA[Dario Amodei]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Dario Amodei.html</link><guid isPermaLink="false">Authors/Dario Amodei.md</guid><pubDate>Sat, 02 Nov 2024 21:22:17 GMT</pubDate></item><item><title><![CDATA[Dave Cummings]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Dave Cummings.html</link><guid isPermaLink="false">Authors/Dave Cummings.md</guid><pubDate>Sat, 02 Nov 2024 21:21:11 GMT</pubDate></item><item><title><![CDATA[David Dohan]]></title><description><![CDATA[ 
 ]]></description><link>Authors/David Dohan.html</link><guid isPermaLink="false">Authors/David Dohan.md</guid><pubDate>Sat, 02 Nov 2024 21:43:23 GMT</pubDate></item><item><title><![CDATA[Dawn Song]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Dawn Song.html</link><guid isPermaLink="false">Authors/Dawn Song.md</guid><pubDate>Sat, 02 Nov 2024 20:13:56 GMT</pubDate></item><item><title><![CDATA[Dzmitry Bahdanau]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Dzmitry Bahdanau.html</link><guid isPermaLink="false">Authors/Dzmitry Bahdanau.md</guid><pubDate>Sun, 03 Nov 2024 20:23:40 GMT</pubDate></item><item><title><![CDATA[Elizabeth Barnes]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Elizabeth Barnes.html</link><guid isPermaLink="false">Authors/Elizabeth Barnes.md</guid><pubDate>Sat, 02 Nov 2024 21:21:15 GMT</pubDate></item><item><title><![CDATA[Ellen Jiang]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Ellen Jiang.html</link><guid isPermaLink="false">Authors/Ellen Jiang.md</guid><pubDate>Sat, 02 Nov 2024 21:43:25 GMT</pubDate></item><item><title><![CDATA[Eric P. Xing]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Eric P. Xing.html</link><guid isPermaLink="false">Authors/Eric P. Xing.md</guid><pubDate>Sat, 02 Nov 2024 21:34:10 GMT</pubDate></item><item><title><![CDATA[Evan Morikawa]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Evan Morikawa.html</link><guid isPermaLink="false">Authors/Evan Morikawa.md</guid><pubDate>Sat, 02 Nov 2024 21:21:57 GMT</pubDate></item><item><title><![CDATA[Felipe Petroski Such]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Felipe Petroski Such.html</link><guid isPermaLink="false">Authors/Felipe Petroski Such.md</guid><pubDate>Sat, 02 Nov 2024 21:21:10 GMT</pubDate></item><item><title><![CDATA[Felix Hill]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Felix Hill.html</link><guid isPermaLink="false">Authors/Felix Hill.md</guid><pubDate>Sat, 02 Nov 2024 21:00:31 GMT</pubDate></item><item><title><![CDATA[Fotios Chantzis]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Fotios Chantzis.html</link><guid isPermaLink="false">Authors/Fotios Chantzis.md</guid><pubDate>Sat, 02 Nov 2024 21:21:13 GMT</pubDate></item><item><title><![CDATA[Girish Sastry]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Girish Sastry.html</link><guid isPermaLink="false">Authors/Girish Sastry.md</guid><pubDate>Sat, 02 Nov 2024 21:20:53 GMT</pubDate></item><item><title><![CDATA[Greg Brockman]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Greg Brockman.html</link><guid isPermaLink="false">Authors/Greg Brockman.md</guid><pubDate>Sat, 02 Nov 2024 21:20:34 GMT</pubDate></item><item><title><![CDATA[Gretchen Krueger]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Gretchen Krueger.html</link><guid isPermaLink="false">Authors/Gretchen Krueger.md</guid><pubDate>Sat, 02 Nov 2024 21:20:48 GMT</pubDate></item><item><title><![CDATA[Hao Zhang]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Hao Zhang.html</link><guid isPermaLink="false">Authors/Hao Zhang.md</guid><pubDate>Sat, 02 Nov 2024 21:34:13 GMT</pubDate></item><item><title><![CDATA[Harm de Vries]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Harm de Vries.html</link><guid isPermaLink="false">Authors/Harm de Vries.md</guid><pubDate>Sun, 03 Nov 2024 20:23:38 GMT</pubDate></item><item><title><![CDATA[Harri Edwards]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Harri Edwards.html</link><guid isPermaLink="false">Authors/Harri Edwards.md</guid><pubDate>Sat, 02 Nov 2024 21:19:10 GMT</pubDate></item><item><title><![CDATA[Heewoo Jun]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Heewoo Jun.html</link><guid isPermaLink="false">Authors/Heewoo Jun.md</guid><pubDate>Sat, 02 Nov 2024 20:49:29 GMT</pubDate></item><item><title><![CDATA[Heidy Khlaaf]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Heidy Khlaaf.html</link><guid isPermaLink="false">Authors/Heidy Khlaaf.md</guid><pubDate>Sat, 02 Nov 2024 21:20:51 GMT</pubDate></item><item><title><![CDATA[Henrique Ponde de Oliveira Pinto]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Henrique Ponde de Oliveira Pinto.html</link><guid isPermaLink="false">Authors/Henrique Ponde de Oliveira Pinto.md</guid><pubDate>Sat, 02 Nov 2024 21:18:37 GMT</pubDate></item><item><title><![CDATA[Henryk Michalewski]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Henryk Michalewski.html</link><guid isPermaLink="false">Authors/Henryk Michalewski.md</guid><pubDate>Sat, 02 Nov 2024 21:43:21 GMT</pubDate></item><item><title><![CDATA[Igor Babuschkin]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Igor Babuschkin.html</link><guid isPermaLink="false">Authors/Igor Babuschkin.md</guid><pubDate>Sat, 02 Nov 2024 21:21:28 GMT</pubDate></item><item><title><![CDATA[Ilya Sutskever]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Ilya Sutskever.html</link><guid isPermaLink="false">Authors/Ilya Sutskever.md</guid><pubDate>Sat, 02 Nov 2024 21:22:23 GMT</pubDate></item><item><title><![CDATA[Ion Stoica]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Ion Stoica.html</link><guid isPermaLink="false">Authors/Ion Stoica.md</guid><pubDate>Sat, 02 Nov 2024 21:34:16 GMT</pubDate></item><item><title><![CDATA[Isaac Cowhey]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Isaac Cowhey.html</link><guid isPermaLink="false">Authors/Isaac Cowhey.md</guid><pubDate>Sat, 02 Nov 2024 19:07:09 GMT</pubDate></item><item><title><![CDATA[Jacob Austin]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Jacob Austin.html</link><guid isPermaLink="false">Authors/Jacob Austin.md</guid><pubDate>Sat, 02 Nov 2024 21:43:13 GMT</pubDate></item><item><title><![CDATA[Jacob Hilton]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Jacob Hilton.html</link><guid isPermaLink="false">Authors/Jacob Hilton.md</guid><pubDate>Sat, 02 Nov 2024 20:31:02 GMT</pubDate></item><item><title><![CDATA[Jacob Steinhardt]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Jacob Steinhardt.html</link><guid isPermaLink="false">Authors/Jacob Steinhardt.md</guid><pubDate>Sat, 02 Nov 2024 20:14:03 GMT</pubDate></item><item><title><![CDATA[Jan Leike]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Jan Leike.html</link><guid isPermaLink="false">Authors/Jan Leike.md</guid><pubDate>Sat, 02 Nov 2024 21:21:49 GMT</pubDate></item><item><title><![CDATA[Jared Kaplan]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Jared Kaplan.html</link><guid isPermaLink="false">Authors/Jared Kaplan.md</guid><pubDate>Sat, 02 Nov 2024 21:18:43 GMT</pubDate></item><item><title><![CDATA[Jerry Tworek]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Jerry Tworek.html</link><guid isPermaLink="false">Authors/Jerry Tworek.md</guid><pubDate>Sat, 02 Nov 2024 20:49:52 GMT</pubDate></item><item><title><![CDATA[Jie Tang]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Jie Tang.html</link><guid isPermaLink="false">Authors/Jie Tang.md</guid><pubDate>Sat, 02 Nov 2024 21:21:26 GMT</pubDate></item><item><title><![CDATA[John Schulman]]></title><description><![CDATA[ 
 ]]></description><link>Authors/John Schulman.html</link><guid isPermaLink="false">Authors/John Schulman.md</guid><pubDate>Sat, 02 Nov 2024 20:50:54 GMT</pubDate></item><item><title><![CDATA[Joseph E. Gonzalez]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Joseph E. Gonzalez.html</link><guid isPermaLink="false">Authors/Joseph E. Gonzalez.md</guid><pubDate>Sat, 02 Nov 2024 21:34:14 GMT</pubDate></item><item><title><![CDATA[Josh Achiam]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Josh Achiam.html</link><guid isPermaLink="false">Authors/Josh Achiam.md</guid><pubDate>Sat, 02 Nov 2024 21:21:51 GMT</pubDate></item><item><title><![CDATA[Julian Michael]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Julian Michael.html</link><guid isPermaLink="false">Authors/Julian Michael.md</guid><pubDate>Sat, 02 Nov 2024 21:00:25 GMT</pubDate></item><item><title><![CDATA[Karl Cobbe]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Karl Cobbe.html</link><guid isPermaLink="false">Authors/Karl Cobbe.md</guid><pubDate>Sat, 02 Nov 2024 20:49:01 GMT</pubDate></item><item><title><![CDATA[Katie Mayer]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Katie Mayer.html</link><guid isPermaLink="false">Authors/Katie Mayer.md</guid><pubDate>Sat, 02 Nov 2024 21:22:10 GMT</pubDate></item><item><title><![CDATA[Lianmin Zheng]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Lianmin Zheng.html</link><guid isPermaLink="false">Authors/Lianmin Zheng.md</guid><pubDate>Sat, 02 Nov 2024 21:33:28 GMT</pubDate></item><item><title><![CDATA[Lukasz Kaiser]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Lukasz Kaiser.html</link><guid isPermaLink="false">Authors/Lukasz Kaiser.md</guid><pubDate>Sat, 02 Nov 2024 20:49:39 GMT</pubDate></item><item><title><![CDATA[Maarten Bosma]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Maarten Bosma.html</link><guid isPermaLink="false">Authors/Maarten Bosma.md</guid><pubDate>Sat, 02 Nov 2024 21:43:19 GMT</pubDate></item><item><title><![CDATA[Mantas Mazeika]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Mantas Mazeika.html</link><guid isPermaLink="false">Authors/Mantas Mazeika.md</guid><pubDate>Sat, 02 Nov 2024 20:13:50 GMT</pubDate></item><item><title><![CDATA[Mark Chen]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Mark Chen.html</link><guid isPermaLink="false">Authors/Mark Chen.md</guid><pubDate>Sat, 02 Nov 2024 20:49:23 GMT</pubDate></item><item><title><![CDATA[Matthew Knight]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Matthew Knight.html</link><guid isPermaLink="false">Authors/Matthew Knight.md</guid><pubDate>Sat, 02 Nov 2024 21:22:02 GMT</pubDate></item><item><title><![CDATA[Matthias Plappert]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Matthias Plappert.html</link><guid isPermaLink="false">Authors/Matthias Plappert.md</guid><pubDate>Sat, 02 Nov 2024 20:49:45 GMT</pubDate></item><item><title><![CDATA[Maxwell Nye]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Maxwell Nye.html</link><guid isPermaLink="false">Authors/Maxwell Nye.md</guid><pubDate>Sat, 02 Nov 2024 21:43:17 GMT</pubDate></item><item><title><![CDATA[Michael Jordan]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Michael Jordan.html</link><guid isPermaLink="false">Authors/Michael Jordan.md</guid><pubDate>Sat, 02 Nov 2024 21:38:03 GMT</pubDate></item><item><title><![CDATA[Michael Petrov]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Michael Petrov.html</link><guid isPermaLink="false">Authors/Michael Petrov.md</guid><pubDate>Sat, 02 Nov 2024 21:20:50 GMT</pubDate></item><item><title><![CDATA[Michael Terry]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Michael Terry.html</link><guid isPermaLink="false">Authors/Michael Terry.md</guid><pubDate>Sat, 02 Nov 2024 21:43:29 GMT</pubDate></item><item><title><![CDATA[Mikhail Pavlov]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Mikhail Pavlov.html</link><guid isPermaLink="false">Authors/Mikhail Pavlov.md</guid><pubDate>Sat, 02 Nov 2024 21:21:02 GMT</pubDate></item><item><title><![CDATA[Miles Brundage]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Miles Brundage.html</link><guid isPermaLink="false">Authors/Miles Brundage.md</guid><pubDate>Sat, 02 Nov 2024 21:22:05 GMT</pubDate></item><item><title><![CDATA[Mira Murati]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Mira Murati.html</link><guid isPermaLink="false">Authors/Mira Murati.md</guid><pubDate>Sat, 02 Nov 2024 21:22:07 GMT</pubDate></item><item><title><![CDATA[Mohammad Bavarian]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Mohammad Bavarian.html</link><guid isPermaLink="false">Authors/Mohammad Bavarian.md</guid><pubDate>Sat, 02 Nov 2024 20:49:17 GMT</pubDate></item><item><title><![CDATA[Nicholas Joseph]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Nicholas Joseph.html</link><guid isPermaLink="false">Authors/Nicholas Joseph.md</guid><pubDate>Sat, 02 Nov 2024 21:20:32 GMT</pubDate></item><item><title><![CDATA[Nick Ryder]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Nick Ryder.html</link><guid isPermaLink="false">Authors/Nick Ryder.md</guid><pubDate>Sat, 02 Nov 2024 21:21:00 GMT</pubDate></item><item><title><![CDATA[Nikita Nangia]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Nikita Nangia.html</link><guid isPermaLink="false">Authors/Nikita Nangia.md</guid><pubDate>Sat, 02 Nov 2024 21:05:46 GMT</pubDate></item><item><title><![CDATA[Nikolas Tezak]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Nikolas Tezak.html</link><guid isPermaLink="false">Authors/Nikolas Tezak.md</guid><pubDate>Sat, 02 Nov 2024 21:21:25 GMT</pubDate></item><item><title><![CDATA[Omer Levy]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Omer Levy.html</link><guid isPermaLink="false">Authors/Omer Levy.md</guid><pubDate>Sat, 02 Nov 2024 21:00:37 GMT</pubDate></item><item><title><![CDATA[Oren Etzioni]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Oren Etzioni.html</link><guid isPermaLink="false">Authors/Oren Etzioni.md</guid><pubDate>Sat, 02 Nov 2024 19:07:16 GMT</pubDate></item><item><title><![CDATA[Owain Evans]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Owain Evans.html</link><guid isPermaLink="false">Authors/Owain Evans.md</guid><pubDate>Sat, 02 Nov 2024 20:31:09 GMT</pubDate></item><item><title><![CDATA[Oyvind Tafjord]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Oyvind Tafjord.html</link><guid isPermaLink="false">Authors/Oyvind Tafjord.md</guid><pubDate>Sat, 02 Nov 2024 19:07:46 GMT</pubDate></item><item><title><![CDATA[Pamela Mishkin]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Pamela Mishkin.html</link><guid isPermaLink="false">Authors/Pamela Mishkin.md</guid><pubDate>Sat, 02 Nov 2024 21:20:55 GMT</pubDate></item><item><title><![CDATA[Peter Clark]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Peter Clark.html</link><guid isPermaLink="false">Authors/Peter Clark.md</guid><pubDate>Sat, 02 Nov 2024 19:06:52 GMT</pubDate></item><item><title><![CDATA[Peter Welinder]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Peter Welinder.html</link><guid isPermaLink="false">Authors/Peter Welinder.md</guid><pubDate>Sat, 02 Nov 2024 21:22:12 GMT</pubDate></item><item><title><![CDATA[Philippe Tillet]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Philippe Tillet.html</link><guid isPermaLink="false">Authors/Philippe Tillet.md</guid><pubDate>Sat, 02 Nov 2024 21:21:08 GMT</pubDate></item><item><title><![CDATA[Qiming Yuan]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Qiming Yuan.html</link><guid isPermaLink="false">Authors/Qiming Yuan.md</guid><pubDate>Sat, 02 Nov 2024 21:18:31 GMT</pubDate></item><item><title><![CDATA[Quoc Le, Charles Sutton]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Quoc Le, Charles Sutton.html</link><guid isPermaLink="false">Authors/Quoc Le, Charles Sutton.md</guid><pubDate>Sat, 02 Nov 2024 21:43:31 GMT</pubDate></item><item><title><![CDATA[Raul Puri]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Raul Puri.html</link><guid isPermaLink="false">Authors/Raul Puri.md</guid><pubDate>Sat, 02 Nov 2024 21:20:42 GMT</pubDate></item><item><title><![CDATA[Reiichiro Nakano]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Reiichiro Nakano.html</link><guid isPermaLink="false">Authors/Reiichiro Nakano.md</guid><pubDate>Sat, 02 Nov 2024 20:50:13 GMT</pubDate></item><item><title><![CDATA[Rowan Zellers]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Rowan Zellers.html</link><guid isPermaLink="false">Authors/Rowan Zellers.md</guid><pubDate>Sat, 02 Nov 2024 19:37:36 GMT</pubDate></item><item><title><![CDATA[Sam McCandlish]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Sam McCandlish.html</link><guid isPermaLink="false">Authors/Sam McCandlish.md</guid><pubDate>Sat, 02 Nov 2024 21:22:20 GMT</pubDate></item><item><title><![CDATA[Samuel R. Bowman]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Samuel R. Bowman.html</link><guid isPermaLink="false">Authors/Samuel R. Bowman.md</guid><pubDate>Sat, 02 Nov 2024 21:00:43 GMT</pubDate></item><item><title><![CDATA[Scott Gray]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Scott Gray.html</link><guid isPermaLink="false">Authors/Scott Gray.md</guid><pubDate>Sat, 02 Nov 2024 21:20:59 GMT</pubDate></item><item><title><![CDATA[Shantanu Jain]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Shantanu Jain.html</link><guid isPermaLink="false">Authors/Shantanu Jain.md</guid><pubDate>Sat, 02 Nov 2024 21:21:32 GMT</pubDate></item><item><title><![CDATA[Siyuan Zhuang]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Siyuan Zhuang.html</link><guid isPermaLink="false">Authors/Siyuan Zhuang.md</guid><pubDate>Sat, 02 Nov 2024 21:33:39 GMT</pubDate></item><item><title><![CDATA[Stephanie Lin]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Stephanie Lin.html</link><guid isPermaLink="false">Authors/Stephanie Lin.md</guid><pubDate>Sat, 02 Nov 2024 20:30:56 GMT</pubDate></item><item><title><![CDATA[Steven Basart]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Steven Basart.html</link><guid isPermaLink="false">Authors/Steven Basart.md</guid><pubDate>Sat, 02 Nov 2024 20:13:35 GMT</pubDate></item><item><title><![CDATA[Suchir Balaji]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Suchir Balaji.html</link><guid isPermaLink="false">Authors/Suchir Balaji.md</guid><pubDate>Sat, 02 Nov 2024 21:21:30 GMT</pubDate></item><item><title><![CDATA[Tianle Li]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Tianle Li.html</link><guid isPermaLink="false">Authors/Tianle Li.md</guid><pubDate>Sat, 02 Nov 2024 21:37:59 GMT</pubDate></item><item><title><![CDATA[Tushar Khot]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Tushar Khot.html</link><guid isPermaLink="false">Authors/Tushar Khot.md</guid><pubDate>Sat, 02 Nov 2024 19:07:21 GMT</pubDate></item><item><title><![CDATA[Vedant Misra]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Vedant Misra.html</link><guid isPermaLink="false">Authors/Vedant Misra.md</guid><pubDate>Sat, 02 Nov 2024 21:21:54 GMT</pubDate></item><item><title><![CDATA[Vineet Kosaraju]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Vineet Kosaraju.html</link><guid isPermaLink="false">Authors/Vineet Kosaraju.md</guid><pubDate>Sat, 02 Nov 2024 20:49:11 GMT</pubDate></item><item><title><![CDATA[Wei-Lin Chiang]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Wei-Lin Chiang.html</link><guid isPermaLink="false">Authors/Wei-Lin Chiang.md</guid><pubDate>Sat, 02 Nov 2024 21:33:37 GMT</pubDate></item><item><title><![CDATA[William Hebgen Guss]]></title><description><![CDATA[ 
 ]]></description><link>Authors/William Hebgen Guss.html</link><guid isPermaLink="false">Authors/William Hebgen Guss.md</guid><pubDate>Sat, 02 Nov 2024 21:21:19 GMT</pubDate></item><item><title><![CDATA[William Saunders]]></title><description><![CDATA[ 
 ]]></description><link>Authors/William Saunders.html</link><guid isPermaLink="false">Authors/William Saunders.md</guid><pubDate>Sat, 02 Nov 2024 21:21:34 GMT</pubDate></item><item><title><![CDATA[Wojciech Zaremba]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Wojciech Zaremba.html</link><guid isPermaLink="false">Authors/Wojciech Zaremba.md</guid><pubDate>Sat, 02 Nov 2024 21:22:25 GMT</pubDate></item><item><title><![CDATA[Yada Pruksachatkun]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Yada Pruksachatkun.html</link><guid isPermaLink="false">Authors/Yada Pruksachatkun.md</guid><pubDate>Sat, 02 Nov 2024 21:05:29 GMT</pubDate></item><item><title><![CDATA[Yejin Choi]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Yejin Choi.html</link><guid isPermaLink="false">Authors/Yejin Choi.md</guid><pubDate>Sat, 02 Nov 2024 19:38:10 GMT</pubDate></item><item><title><![CDATA[Ying Sheng]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Ying Sheng.html</link><guid isPermaLink="false">Authors/Ying Sheng.md</guid><pubDate>Sat, 02 Nov 2024 21:33:42 GMT</pubDate></item><item><title><![CDATA[Yonatan Bisk]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Yonatan Bisk.html</link><guid isPermaLink="false">Authors/Yonatan Bisk.md</guid><pubDate>Sat, 02 Nov 2024 19:37:49 GMT</pubDate></item><item><title><![CDATA[Yonghao Zhuang]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Yonghao Zhuang.html</link><guid isPermaLink="false">Authors/Yonghao Zhuang.md</guid><pubDate>Sat, 02 Nov 2024 21:33:45 GMT</pubDate></item><item><title><![CDATA[Yuri Burda]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Yuri Burda.html</link><guid isPermaLink="false">Authors/Yuri Burda.md</guid><pubDate>Sat, 02 Nov 2024 21:19:23 GMT</pubDate></item><item><title><![CDATA[Zhanghao Wu]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Zhanghao Wu.html</link><guid isPermaLink="false">Authors/Zhanghao Wu.md</guid><pubDate>Sat, 02 Nov 2024 21:33:43 GMT</pubDate></item><item><title><![CDATA[Zhuohan Li]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Zhuohan Li.html</link><guid isPermaLink="false">Authors/Zhuohan Li.md</guid><pubDate>Sat, 02 Nov 2024 21:34:07 GMT</pubDate></item><item><title><![CDATA[Zi Lin]]></title><description><![CDATA[ 
 ]]></description><link>Authors/Zi Lin.html</link><guid isPermaLink="false">Authors/Zi Lin.md</guid><pubDate>Sat, 02 Nov 2024 21:34:05 GMT</pubDate></item><item><title><![CDATA[AI2 Reasoning Challenge (ARC)]]></title><description><![CDATA[ 
 <br>Paper: <a data-href="Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge" href="Papers/Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge" class="internal-link" target="_self" rel="noopener nofollow">Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge</a><br><br>The goal: To measure a model's ability to correctly answer questions and demonstrate sound reasoning.<br> The test: To correctly answer more than 7000 grade-school science questions.<br><br> 7787 four-option multiple-choice science questions that range from a 3rd to 9th-grade difficulty level.<br>More comprehensive and difficult benchmark than previous QA benchmarks:<br>
<br><a data-href="Stanford Question and Answer Dataset (SQuAD)" href="Stanford Question and Answer Dataset (SQuAD)" class="internal-link" target="_self" rel="noopener nofollow">Stanford Question and Answer Dataset (SQuAD)</a>
<br><a data-href="Stanford Natural Language Inference (SNLI)" href="Stanford Natural Language Inference (SNLI)" class="internal-link" target="_self" rel="noopener nofollow">Stanford Natural Language Inference (SNLI)</a> corpus, 
<br>These only measured a model’s ability to extract the correct answer from a passage.<br><br>
<br>Varied and challenging dataset
<br>Pushes AI vendors to improve QA abilities – not just through fact retrieval but by integrating information from several sentences.  
<br><br>
<br>Only consists of scientific questions 
]]></description><link>Benchmarks/AI2 Reasoning Challenge (ARC).html</link><guid isPermaLink="false">Benchmarks/AI2 Reasoning Challenge (ARC).md</guid><pubDate>Sat, 02 Nov 2024 19:31:39 GMT</pubDate></item><item><title><![CDATA[Chatbot Arena]]></title><description><![CDATA[ 
 <br>Paper: <a data-href="Chatbot Arena- An Open Platform for Evaluating LLMs by Human Preference" href="Papers/Chatbot Arena- An Open Platform for Evaluating LLMs by Human Preference.html" class="internal-link" target="_self" rel="noopener nofollow">Chatbot Arena- An Open Platform for Evaluating LLMs by Human Preference</a><br><br>The goal: To assess a model's understanding of common-sense reasoning and its ability to resolve ambiguous pronouns in sentences.<br>The test: The model is given sentences with ambiguous pronouns and must correctly identify which noun the pronoun refers to.]]></description><link>Benchmarks/Chatbot Arena.html</link><guid isPermaLink="false">Benchmarks/Chatbot Arena.md</guid><pubDate>Sat, 02 Nov 2024 21:38:31 GMT</pubDate></item><item><title><![CDATA[GLUE (General Language Understanding Evaluation)]]></title><description><![CDATA[ 
 <br>Paper: <a data-href="GLUE- A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding" href="Papers/GLUE- A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding.html" class="internal-link" target="_self" rel="noopener nofollow">GLUE- A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding</a><br>The goal: To measure a model's ability to perform a variety of natural language understanding tasks.<br>The test: The model is tested on a suite of language tasks, including sentiment analysis, textual entailment, and sentence similarity.<br><br>Sentiment analysis is the process of determining the emotional tone or opinion expressed in a piece of text, typically categorizing it as positive, negative, or neutral.<br>Textual entailment is the task of determining whether a given piece of text (the hypothesis) can be inferred or logically follows from another piece of text (the premise).<br>Here's an example of textual entailment:<br>Premise: "The cat is on the mat."
Hypothesis: "There is a cat."
Copy<br>This is a positive textual entailment because the second sentence (hypothesis) can be inferred from the first sentence (premise).]]></description><link>Benchmarks/GLUE (General Language Understanding Evaluation).html</link><guid isPermaLink="false">Benchmarks/GLUE (General Language Understanding Evaluation).md</guid><pubDate>Sat, 02 Nov 2024 21:02:17 GMT</pubDate></item><item><title><![CDATA[GSM8K (Grade School Math 8K)]]></title><description><![CDATA[ 
 <br>Paper: <a data-href="Training Verifiers to Solve Math Word Problems" href="Papers/Training Verifiers to Solve Math Word Problems.html" class="internal-link" target="_self" rel="noopener nofollow">Training Verifiers to Solve Math Word Problems</a><br><br>The goal: To evaluate a model’s capability in solving grade-school-level math problems.<br>The test: The model is presented with more than 8,000 grade-school math word problems and must solve them correctly.<br><br> Multi-step mathematical reasoning abilities. <br> 8,500 grade-school-level math word problems devised by humans, which is divided into 7,500 training problems and 1,00 test problems. <br>The solution to each problem is collected in natural language form as opposed to a mathematical expression. <br>does not describe how evaluation is done <br><br>
<br>Mathematical reasoning thus reveals a critical weakness in modern language models.
<br>Problems are framed with high linguistic diversity 
<br><br>
<br>Problems are relatively simple to solve, so the benchmark could be obsolete fairly soon 
]]></description><link>Benchmarks/GSM8K (Grade School Math 8K).html</link><guid isPermaLink="false">Benchmarks/GSM8K (Grade School Math 8K).md</guid><pubDate>Sat, 02 Nov 2024 20:54:42 GMT</pubDate></item><item><title><![CDATA[HellaSwag (Harder Endings, Longer contexts and Low-shot Activities for Situations With Adversarial Generations)]]></title><description><![CDATA[ 
 <br>Paper: <a data-href="HellaSwag- Can a Machine Really Finish Your Sentence?" href="Papers/HellaSwag- Can a Machine Really Finish Your Sentence" class="internal-link" target="_self" rel="noopener nofollow">HellaSwag- Can a Machine Really Finish Your Sentence?</a><br><br>The goal: To measure a model's ability to choose the most plausible ending for a given context, especially in scenarios where the context is longer, and the tasks are more challenging.<br>The test: The model is given a short story or context and must select the correct ending from a set of options. There are options that are tricky or misleading.<br><br>commonsense reasoning and natural language inference (NLI) capabilities of LLMs through sentence completion exercises<br>Successor to the <a data-href="SWAG" href="SWAG" class="internal-link" target="_self" rel="noopener nofollow">SWAG</a> benchmark<br>Segment of a video caption as an initial context and four possible endings, of which only one is correct.  Average human performance is 95% <br>Wrong answers generated through generation of adversarial endings with increasing difficulty <br><br>
<br>Similar to ARC, it evaluates a model’s common sense and reasoning, as opposed to mere ability to recall facts
<br>Thoroughly curated dataset: all easily completed contexts from the SWAG dataset were discarded and human assistants sifted through the adversarial endings and chose the best 70,000. 
<br><br>
<br>General knowledge – doesn’t test common sense reasoning for specialised domains.  
]]></description><link>Benchmarks/HellaSwag (Harder Endings, Longer contexts and Low-shot Activities for Situations With Adversarial Generations).html</link><guid isPermaLink="false">Benchmarks/HellaSwag (Harder Endings, Longer contexts and Low-shot Activities for Situations With Adversarial Generations).md</guid><pubDate>Sat, 02 Nov 2024 19:47:59 GMT</pubDate></item><item><title><![CDATA[HumanEval]]></title><description><![CDATA[ 
 <br>Paper: <a data-href="Evaluating Large Language Models Trained on Code" href="Papers/Evaluating Large Language Models Trained on Code.html" class="internal-link" target="_self" rel="noopener nofollow">Evaluating Large Language Models Trained on Code</a><br><br>The goal: To measure a model’s ability to write correct Python code to solve programming problems.<br>The test: The model is given programming tasks, and its output is compared against expected solutions to determine correctness.<br><br> Generate functionally correct code; <br>HumanEval dataset<br>
164 diverse coding challenges that include several unit tests (7.7 on average). <br>pass@k metric:<br>
Probability that at least one of k generated code samples pass the coding challenge’s unit tests, given that there are c correct samples from n generated samples.<br>Improves on BLEU (bilingual evaluation understudy) metric - was used to assess the textual similarity of model-generated coding solutions compared with human ones. The problem with this approach, however as it doesn’t evaluate the functional correctness of the generated solution; <br><br>
<br>A good indication of a model’s coding capability 
<br>Unit testing mirrors the way humans evaluate code functionality 
<br><br>
<br>The HumanEval dataset doesn’t comprehensively capture how coding models are used in practice. For instance, it doesn’t test for aspects such as writing tests, code explanation, code infilling, or docstring generation.
]]></description><link>Benchmarks/HumanEval.html</link><guid isPermaLink="false">Benchmarks/HumanEval.md</guid><pubDate>Sat, 02 Nov 2024 21:30:30 GMT</pubDate></item><item><title><![CDATA[MBPP (Mostly Basic Programming Problems)]]></title><description><![CDATA[ 
 <br>Paper: <a data-href="Program Synthesis with Large Language Models" href="Papers/Program Synthesis with Large Language Models.html" class="internal-link" target="_self" rel="noopener nofollow">Program Synthesis with Large Language Models</a><br><br>The goal: To evaluate a model's basic programming skills, focusing on the ability to solve simple coding problems.<br>The test: The model is presented with a series of basic programming problems and is judged on the correctness and efficiency of its solutions.]]></description><link>Benchmarks/MBPP (Mostly Basic Programming Problems).html</link><guid isPermaLink="false">Benchmarks/MBPP (Mostly Basic Programming Problems).md</guid><pubDate>Sat, 02 Nov 2024 21:43:00 GMT</pubDate></item><item><title><![CDATA[MMLU (Massive Multitask Language Understanding)]]></title><description><![CDATA[ 
 <br>Paper: <a data-href="Measuring Massive Multitask Language Understanding" href="Papers/Measuring Massive Multitask Language Understanding.html" class="internal-link" target="_self" rel="noopener nofollow">Measuring Massive Multitask Language Understanding</a><br><br>The goal: To assess a model's ability to understand and respond correctly across a wide range of subjects, from elementary knowledge to advanced topics.<br>The test: The model is tested with more than 15,000 questions from over 50 different subjects, including humanities, sciences, and social sciences, with questions designed to reflect varying levels of difficulty.<br><br>How well a model understands language and, subsequently, its ability to solve problems with the knowledge to which it was exposed during training. <br>Focused on <a data-href="Natural Language Understanding" href="Concepts/Natural Language Understanding.html" class="internal-link" target="_self" rel="noopener nofollow">Natural Language Understanding</a><br>15,908 questions divided into  57 tasks<br>
STEM, humanities,  social sciences, and other subjects from an elementary to an advanced professional level.  Departure from <a data-href="SuperGLUE" href="Benchmarks/SuperGLUE.html" class="internal-link" target="_self" rel="noopener nofollow">SuperGLUE</a> with a focus on specialized knowledge<br>Does not mention how it is quantiatively evaluated<br><br>
<br>Tests a broad range of subjects at various levels of difficulty 
<br>Broad corpus helps identify areas of general knowledge in which models are deficient
<br><br>
<br>Limited information on how corpus was constructed
<br>Dataset is shown to have numerous errors (See: <a data-href="Errors in the MMLU- The Deep Learning Benchmark is Wrong Surprisingly Often" href="Webpages/Errors in the MMLU- The Deep Learning Benchmark is Wrong Surprisingly Often.html" class="internal-link" target="_self" rel="noopener nofollow">Errors in the MMLU- The Deep Learning Benchmark is Wrong Surprisingly Often</a>)
]]></description><link>Benchmarks/MMLU (Massive Multitask Language Understanding).html</link><guid isPermaLink="false">Benchmarks/MMLU (Massive Multitask Language Understanding).md</guid><pubDate>Sat, 02 Nov 2024 20:19:17 GMT</pubDate></item><item><title><![CDATA[MT Bench]]></title><description><![CDATA[ 
 <br>Paper: <a data-href="Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena" href="Papers/Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena.html" class="internal-link" target="_self" rel="noopener nofollow">Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena</a><br><br>Multi-turn dialogs<br>human evaluation through crowdsourced platform<br>crowd-sourced platform that allows users to evaluate a variety of chatbots by entering a prompt and comparing the two responses side-by-side. Users vote on best response<br>eight main types of user prompts: <br>
<br>writing, 
<br>roleplay, 
<br>extraction, 
<br>reasoning, 
<br>math, 
<br>coding, 
<br>knowledge I (STEM), 
<br>knowledge II (humanities)
<br>160 questions.<br><br>
<br>Measures a model’s ability to answer subsequent, related questions
<br><br>
<br>Though carefully curated, the dataset is small
<br>Hard to simulate the broad and unpredictable nature of conversations
]]></description><link>Benchmarks/MT Bench.html</link><guid isPermaLink="false">Benchmarks/MT Bench.md</guid><pubDate>Sat, 02 Nov 2024 21:51:01 GMT</pubDate></item><item><title><![CDATA[SuperGLUE]]></title><description><![CDATA[ 
 <br>Paper: <a data-href="SuperGLUE- A Stickier Benchmark for General-Purpose Language Understanding Systems" href="Papers/SuperGLUE- A Stickier Benchmark for General-Purpose Language Understanding Systems.html" class="internal-link" target="_self" rel="noopener nofollow">SuperGLUE- A Stickier Benchmark for General-Purpose Language Understanding Systems</a><br><br>Tests <a data-href="Natural Language Understanding" href="Concepts/Natural Language Understanding.html" class="internal-link" target="_self" rel="noopener nofollow">Natural Language Understanding</a><br>More diverse and challenging collection of tasks than <a data-href="GLUE (General Language Understanding Evaluation)" href="Benchmarks/GLUE (General Language Understanding Evaluation).html" class="internal-link" target="_self" rel="noopener nofollow">GLUE (General Language Understanding Evaluation)</a><br>Eight subtasks:<br>
<br>Boolean Questions (BoolQ): yes/no QA task
<br>CommitmentBank (CB): truthfulness assessment 
<br>Choice of Plausible Alternatives (COPA): causal reasoning task
<br>Multi-Sentence Reading Comprehension (MultiRC): true/false QA task
<br>Reading Comprehension with Commonsense Reasoning Dataset (ReCoRD): multiple-choice QA task
<br>Recognizing Textual Entailment (RTE): two-class classification task
<br>Word-in-Context (WiC): is a binary classification task
<br>Winograd Schema Challenge (WSC): pronoun resolution problems
<br>Two metrics:<br>
<br>Broad Coverage Diagnostics: to automatically test an LLM’s linguistic, common sense, and general world knowledge
<br>Analysing Gender Bias in Models: an analytical tool for detecting a model’s social biases 
<br><br>
<br>A thorough and diverse range of tasks that test a model’s NLU capabilities
<br><br>
<br>A smaller range of models are tested against SuperGLUE than similar benchmark MMLU 
]]></description><link>Benchmarks/SuperGLUE.html</link><guid isPermaLink="false">Benchmarks/SuperGLUE.md</guid><pubDate>Sat, 02 Nov 2024 21:11:12 GMT</pubDate></item><item><title><![CDATA[TruthfulQA]]></title><description><![CDATA[ 
 <br>Paper: <a data-href="TruthfulQA- Measuring How Models Mimic Human Falsehoods" href="Papers/TruthfulQA- Measuring How Models Mimic Human Falsehoods.html" class="internal-link" target="_self" rel="noopener nofollow">TruthfulQA- Measuring How Models Mimic Human Falsehoods</a><br><br>The goal: To measure a model's ability to generate truthful and factually accurate responses.<br>The test: The model is given more than 800 questions that could easily lead to incorrect or misleading answers, and it is evaluated on how truthful its responses are.<br><br>Deals with <a data-href="Imitative Falsehoods" href="Concepts/Imitative Falsehoods.html" class="internal-link" target="_self" rel="noopener nofollow">Imitative Falsehoods</a><br> 817 questions across 38 categories, such as finance, health, and politics. <br> Two Tasks:<br>
<br>requires the model to generate answers to a series of questions. response is scored between 0 and 1 by human evaluators, where 0 is false and 1 is true. 
<br>instead of generating an answer, the LLM must choose true or false for a series of multiple-choice questions, which are tallied.<br>
Task scores are combined
<br><br>
<br>Diverse dataset
<br>Tests LLMs for hallucinations and encourages model accuracy
<br><br>
<br>Corpus covers general knowledge, so not a great indicator of truthfulness for specialised domains
]]></description><link>Benchmarks/TruthfulQA.html</link><guid isPermaLink="false">Benchmarks/TruthfulQA.md</guid><pubDate>Sat, 02 Nov 2024 20:37:49 GMT</pubDate></item><item><title><![CDATA[Winogrande]]></title><description><![CDATA[ 
 <br>Paper: <a data-href="WinoGrande- An Adversarial Winograd Schema Challenge at Scale" href="Papers/WinoGrande- An Adversarial Winograd Schema Challenge at Scale.html" class="internal-link" target="_self" rel="noopener nofollow">WinoGrande- An Adversarial Winograd Schema Challenge at Scale</a><br><br>The goal: To assess a model's understanding of common-sense reasoning and its ability to resolve ambiguous pronouns in sentences.<br>The test: The model is given sentences with ambiguous pronouns and must correctly identify which noun the pronoun refers to.<br><br> Commonsense reasoning abilities. <br> Pronoun resolution problem where two near-identical sentences have two possible answers, which change based on a trigger word.<br> Based on <a data-href="Winograd Schema Challenge (WSC)" href="Winograd Schema Challenge (WSC)" class="internal-link" target="_self" rel="noopener nofollow">Winograd Schema Challenge (WSC)</a> <br>44,000 well-designed, crowdsource problems<br><br>
<br>Large crowdsourced and algorithmically-curated dataset. 
<br><br>
<br>The presence of annotation artefacts in the dataset. Annotation artefacts are patterns within the data that unintentionally reveal information about the target label. Although AFLITE is designed to remove this, it’s not 100% accurate due to the size of the corpus.
]]></description><link>Benchmarks/Winogrande.html</link><guid isPermaLink="false">Benchmarks/Winogrande.md</guid><pubDate>Sat, 02 Nov 2024 20:44:17 GMT</pubDate></item><item><title><![CDATA[Chain of Thought]]></title><description><![CDATA[<a class="tag" href="?query=tag:papers_to_process" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#papers_to_process</a> 
 <br>From: <a data-href="AI - Overview of common LLM Benchmarks" href="Webpages/AI - Overview of common LLM Benchmarks.html" class="internal-link" target="_self" rel="noopener nofollow">AI - Overview of common LLM Benchmarks</a><br>Chain of Thought (CoT) is a technique used in language models where the model is encouraged to generate a series of intermediate reasoning steps before arriving at the final answer. It mimics how humans often solve complex problems by breaking them down into smaller, manageable steps.<br><br>Question:
"Sarah has 7 apples. 
She gives 3 apples to her friend and then buys 5 more. 
How many apples does Sarah have now?"

Model's Response:

"Sarah starts with 7 apples."
"She gives 3 apples away, so she has 7 - 3 = 4 apples left."
"She buys 5 more apples, so now she has 4 + 5 = 9 apples."
Answer: "Sarah has 9 apples."
Copy<br><br><a data-tooltip-position="top" aria-label="https://www.ibm.com/topics/chain-of-thoughts#f01" rel="noopener nofollow" class="external-link" href="https://www.ibm.com/topics/chain-of-thoughts#f01" target="_blank">IBM - Chain of Thought</a> <br><br><a href=".?query=tag:papers_to_process" class="tag" target="_blank" rel="noopener nofollow">#papers_to_process</a> <br>Boshi Wang, S. M. (2022). Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters. 2717-2739, <a rel="noopener nofollow" class="external-link" href="https://doi.org/10.48550/arXiv.2212.10001" target="_blank">https://doi.org/10.48550/arXiv.2212.10001</a>.<br>Jason Wei, X. W. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models. 36th Conference on Neural Information Processing Systems (NeurIPS 2022).<br>Zheng Chu, J. C. (2023). A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future. ArXiv, abs/2309.15402.<br>Omar Shaikh, H. Z. (2022, December). On Second Thought, Let’s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning. ArXiv, abs/2212.08061. <a rel="noopener nofollow" class="external-link" href="https://doi.org/10.48550/arXiv.2212.08061" target="_blank">https://doi.org/10.48550/arXiv.2212.08061</a>.<br>Zhuosheng Zhang, A. Z. (2022). Automatic Chain of Thought Prompting in Large Language Models. ArXiv, abs/2210.03493. <a rel="noopener nofollow" class="external-link" href="https://doi.org/10.48550/arXiv.2210.03493" target="_blank">https://doi.org/10.48550/arXiv.2210.03493</a>.<br>Zhuosheng Zhang, A. Z. (2023). Multimodal Chain-of-Thought Reasoning in Language Models. ArXiv, abs/2302.00923. <a rel="noopener nofollow" class="external-link" href="https://doi.org/10.48550/arXiv.2302.00923" target="_blank">https://doi.org/10.48550/arXiv.2302.00923</a>.<br>Yao, Z. L. (2023). Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models. ArXiv, abs/2305.16582. <a rel="noopener nofollow" class="external-link" href="https://doi.org/10.48550/arXiv.2305.16582" target="_blank">https://doi.org/10.48550/arXiv.2305.16582</a>.<br>Kashun Shum, S. D. (2023). Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data. ArXiv, abs/2302.12822. <a rel="noopener nofollow" class="external-link" href="https://doi.org/10.48550/arXiv.2302.12822" target="_blank">https://doi.org/10.48550/arXiv.2302.12822</a>.<br>A Vaswani, N. S. (2017). Attention is all you need. Advances in neural information processing systems.<br>Zhengyan Zhang, Y. G. (2021). CPM-2: Large-scale Cost-effective Pre-trained Language Models. AI Open, 2, 216--224.<br>L Zheng, N. G. (2021). When does pretraining help? assessing self-supervised learning for law and the casehold dataset of 53,000+ legal holdings. In Proceedings of the eighteenth international conference on artificial intelligence and law , 159-168.<br>S Roller, E. D. (2020). Recipes for building an open-domain chatbot. arXiv preprint arXiv:2004.13637 .]]></description><link>Concepts/Chain of Thought.html</link><guid isPermaLink="false">Concepts/Chain of Thought.md</guid><pubDate>Sun, 03 Nov 2024 18:18:02 GMT</pubDate></item><item><title><![CDATA[Ecological Validity]]></title><description><![CDATA[ 
 <br><a data-href="Towards Ecologically Valid Research on Language User Interfaces" href="Papers/Towards Ecologically Valid Research on Language User Interfaces.html" class="internal-link" target="_self" rel="noopener nofollow">Towards Ecologically Valid Research on Language User Interfaces</a>]]></description><link>Concepts/Ecological Validity.html</link><guid isPermaLink="false">Concepts/Ecological Validity.md</guid><pubDate>Sun, 03 Nov 2024 20:25:25 GMT</pubDate></item><item><title><![CDATA[Imitative Falsehoods]]></title><description><![CDATA[ 
 ]]></description><link>Concepts/Imitative Falsehoods.html</link><guid isPermaLink="false">Concepts/Imitative Falsehoods.md</guid><pubDate>Sat, 02 Nov 2024 20:37:14 GMT</pubDate></item><item><title><![CDATA[Natural Language Understanding]]></title><description><![CDATA[ 
 ]]></description><link>Concepts/Natural Language Understanding.html</link><guid isPermaLink="false">Concepts/Natural Language Understanding.md</guid><pubDate>Sat, 02 Nov 2024 20:15:30 GMT</pubDate></item><item><title><![CDATA[Chatbot Arena- An Open Platform for Evaluating LLMs by Human Preference]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2403.04132" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/2403.04132" target="_blank">Link</a><br><br><a data-href="Wei-Lin Chiang" href="Authors/Wei-Lin Chiang.html" class="internal-link" target="_self" rel="noopener nofollow">Wei-Lin Chiang</a>, <a data-href="Lianmin Zheng" href="Authors/Lianmin Zheng.html" class="internal-link" target="_self" rel="noopener nofollow">Lianmin Zheng</a>, <a data-href="Ying Sheng" href="Authors/Ying Sheng.html" class="internal-link" target="_self" rel="noopener nofollow">Ying Sheng</a>, <a data-href="Anastasios Nikolas Angelopoulos" href="Authors/Anastasios Nikolas Angelopoulos.html" class="internal-link" target="_self" rel="noopener nofollow">Anastasios Nikolas Angelopoulos</a>, <a data-href="Tianle Li" href="Authors/Tianle Li.html" class="internal-link" target="_self" rel="noopener nofollow">Tianle Li</a>, <a data-href="Dacheng Li" href="Authors/Dacheng Li.html" class="internal-link" target="_self" rel="noopener nofollow">Dacheng Li</a>, <a data-href="Hao Zhang" href="Authors/Hao Zhang.html" class="internal-link" target="_self" rel="noopener nofollow">Hao Zhang</a>, <a data-href="Banghua Zhu" href="Authors/Banghua Zhu.html" class="internal-link" target="_self" rel="noopener nofollow">Banghua Zhu</a>, <a data-href="Michael Jordan" href="Authors/Michael Jordan.html" class="internal-link" target="_self" rel="noopener nofollow">Michael Jordan</a>, <a data-href="Joseph E. Gonzalez" href="Authors/Joseph E. Gonzalez.html" class="internal-link" target="_self" rel="noopener nofollow">Joseph E. Gonzalez</a>, <a data-href="Ion Stoica" href="Authors/Ion Stoica.html" class="internal-link" target="_self" rel="noopener nofollow">Ion Stoica</a><br><br>Large Language Models (LLMs) have unlocked new capabilities and applications; however, evaluating the alignment with human preferences still poses significant challenges. To address this issue, we introduce Chatbot Arena, an open platform for evaluating LLMs based on human preferences. Our methodology employs a pairwise comparison approach and leverages input from a diverse user base through crowdsourcing. The platform has been operational for several months, amassing over 240K votes. This paper describes the platform, analyzes the data we have collected so far, and explains the tried-and-true statistical methods we are using for efficient and accurate evaluation and ranking of models. We confirm that the crowdsourced questions are sufficiently diverse and discriminating and that the crowdsourced human votes are in good agreement with those of expert raters. These analyses collectively establish a robust foundation for the credibility of Chatbot Arena. Because of its unique value and openness, Chatbot Arena has emerged as one of the most referenced LLM leaderboards, widely cited by leading LLM developers and companies. Our demo is publicly available at \url{this https URL}. <br><br><a data-href="Chatbot Arena" href="Benchmarks/Chatbot Arena.html" class="internal-link" target="_self" rel="noopener nofollow">Chatbot Arena</a>]]></description><link>Papers/Chatbot Arena- An Open Platform for Evaluating LLMs by Human Preference.html</link><guid isPermaLink="false">Papers/Chatbot Arena- An Open Platform for Evaluating LLMs by Human Preference.md</guid><pubDate>Sun, 03 Nov 2024 18:24:54 GMT</pubDate></item><item><title><![CDATA[Evaluating Large Language Models Trained on Code]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2107.03374" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/2107.03374" target="_blank">Link</a><br><br><a data-href="Mark Chen" href="Authors/Mark Chen.html" class="internal-link" target="_self" rel="noopener nofollow">Mark Chen</a>, <a data-href="Jerry Tworek" href="Authors/Jerry Tworek.html" class="internal-link" target="_self" rel="noopener nofollow">Jerry Tworek</a>, <a data-href="Heewoo Jun" href="Authors/Heewoo Jun.html" class="internal-link" target="_self" rel="noopener nofollow">Heewoo Jun</a>, <a data-href="Qiming Yuan" href="Authors/Qiming Yuan.html" class="internal-link" target="_self" rel="noopener nofollow">Qiming Yuan</a>, <a data-href="Henrique Ponde de Oliveira Pinto" href="Authors/Henrique Ponde de Oliveira Pinto.html" class="internal-link" target="_self" rel="noopener nofollow">Henrique Ponde de Oliveira Pinto</a>, <a data-href="Jared Kaplan" href="Authors/Jared Kaplan.html" class="internal-link" target="_self" rel="noopener nofollow">Jared Kaplan</a>, <a data-href="Harri Edwards" href="Authors/Harri Edwards.html" class="internal-link" target="_self" rel="noopener nofollow">Harri Edwards</a>, <a data-href="Yuri Burda" href="Authors/Yuri Burda.html" class="internal-link" target="_self" rel="noopener nofollow">Yuri Burda</a>, <a data-href="Nicholas Joseph" href="Authors/Nicholas Joseph.html" class="internal-link" target="_self" rel="noopener nofollow">Nicholas Joseph</a>, <a data-href="Greg Brockman" href="Authors/Greg Brockman.html" class="internal-link" target="_self" rel="noopener nofollow">Greg Brockman</a>, <a data-href="Alex Ray" href="Authors/Alex Ray.html" class="internal-link" target="_self" rel="noopener nofollow">Alex Ray</a>, <a data-href="Raul Puri" href="Authors/Raul Puri.html" class="internal-link" target="_self" rel="noopener nofollow">Raul Puri</a>, <a data-href="Gretchen Krueger" href="Authors/Gretchen Krueger.html" class="internal-link" target="_self" rel="noopener nofollow">Gretchen Krueger</a>, <a data-href="Michael Petrov" href="Authors/Michael Petrov.html" class="internal-link" target="_self" rel="noopener nofollow">Michael Petrov</a>, <a data-href="Heidy Khlaaf" href="Authors/Heidy Khlaaf.html" class="internal-link" target="_self" rel="noopener nofollow">Heidy Khlaaf</a>, <a data-href="Girish Sastry" href="Authors/Girish Sastry.html" class="internal-link" target="_self" rel="noopener nofollow">Girish Sastry</a>, <a data-href="Pamela Mishkin" href="Authors/Pamela Mishkin.html" class="internal-link" target="_self" rel="noopener nofollow">Pamela Mishkin</a>, <a data-href="Brooke Chan" href="Authors/Brooke Chan.html" class="internal-link" target="_self" rel="noopener nofollow">Brooke Chan</a>, <a data-href="Scott Gray" href="Authors/Scott Gray.html" class="internal-link" target="_self" rel="noopener nofollow">Scott Gray</a>, <a data-href="Nick Ryder" href="Authors/Nick Ryder.html" class="internal-link" target="_self" rel="noopener nofollow">Nick Ryder</a>, <a data-href="Mikhail Pavlov" href="Authors/Mikhail Pavlov.html" class="internal-link" target="_self" rel="noopener nofollow">Mikhail Pavlov</a>, <a data-href="Alethea Power" href="Authors/Alethea Power.html" class="internal-link" target="_self" rel="noopener nofollow">Alethea Power</a>, <a data-href="Lukasz Kaiser" href="Authors/Lukasz Kaiser.html" class="internal-link" target="_self" rel="noopener nofollow">Lukasz Kaiser</a>, <a data-href="Mohammad Bavarian" href="Authors/Mohammad Bavarian.html" class="internal-link" target="_self" rel="noopener nofollow">Mohammad Bavarian</a>, <a data-href="Clemens Winter" href="Authors/Clemens Winter.html" class="internal-link" target="_self" rel="noopener nofollow">Clemens Winter</a>, <a data-href="Philippe Tillet" href="Authors/Philippe Tillet.html" class="internal-link" target="_self" rel="noopener nofollow">Philippe Tillet</a>, <a data-href="Felipe Petroski Such" href="Authors/Felipe Petroski Such.html" class="internal-link" target="_self" rel="noopener nofollow">Felipe Petroski Such</a>, <a data-href="Dave Cummings" href="Authors/Dave Cummings.html" class="internal-link" target="_self" rel="noopener nofollow">Dave Cummings</a>, <a data-href="Matthias Plappert" href="Authors/Matthias Plappert.html" class="internal-link" target="_self" rel="noopener nofollow">Matthias Plappert</a>, <a data-href="Fotios Chantzis" href="Authors/Fotios Chantzis.html" class="internal-link" target="_self" rel="noopener nofollow">Fotios Chantzis</a>, <a data-href="Elizabeth Barnes" href="Authors/Elizabeth Barnes.html" class="internal-link" target="_self" rel="noopener nofollow">Elizabeth Barnes</a>, <a data-href="Ariel Herbert-Voss" href="Authors/Ariel Herbert-Voss.html" class="internal-link" target="_self" rel="noopener nofollow">Ariel Herbert-Voss</a>, <a data-href="William Hebgen Guss" href="Authors/William Hebgen Guss.html" class="internal-link" target="_self" rel="noopener nofollow">William Hebgen Guss</a>, <a data-href="Alex Nichol" href="Authors/Alex Nichol.html" class="internal-link" target="_self" rel="noopener nofollow">Alex Nichol</a>, <a data-href="Alex Paino" href="Authors/Alex Paino.html" class="internal-link" target="_self" rel="noopener nofollow">Alex Paino</a>, <a data-href="Nikolas Tezak" href="Authors/Nikolas Tezak.html" class="internal-link" target="_self" rel="noopener nofollow">Nikolas Tezak</a>, <a data-href="Jie Tang" href="Authors/Jie Tang.html" class="internal-link" target="_self" rel="noopener nofollow">Jie Tang</a>, <a data-href="Igor Babuschkin" href="Authors/Igor Babuschkin.html" class="internal-link" target="_self" rel="noopener nofollow">Igor Babuschkin</a>, <a data-href="Suchir Balaji" href="Authors/Suchir Balaji.html" class="internal-link" target="_self" rel="noopener nofollow">Suchir Balaji</a>, <a data-href="Shantanu Jain" href="Authors/Shantanu Jain.html" class="internal-link" target="_self" rel="noopener nofollow">Shantanu Jain</a>, <a data-href="William Saunders" href="Authors/William Saunders.html" class="internal-link" target="_self" rel="noopener nofollow">William Saunders</a>, <a data-href="Christopher Hesse" href="Authors/Christopher Hesse.html" class="internal-link" target="_self" rel="noopener nofollow">Christopher Hesse</a>, <a data-href="Andrew N. Carr" href="Authors/Andrew N. Carr.html" class="internal-link" target="_self" rel="noopener nofollow">Andrew N. Carr</a>, <a data-href="Jan Leike" href="Authors/Jan Leike.html" class="internal-link" target="_self" rel="noopener nofollow">Jan Leike</a>, <a data-href="Josh Achiam" href="Authors/Josh Achiam.html" class="internal-link" target="_self" rel="noopener nofollow">Josh Achiam</a>, <a data-href="Vedant Misra" href="Authors/Vedant Misra.html" class="internal-link" target="_self" rel="noopener nofollow">Vedant Misra</a>, <a data-href="Evan Morikawa" href="Authors/Evan Morikawa.html" class="internal-link" target="_self" rel="noopener nofollow">Evan Morikawa</a>, <a data-href="Alec Radford" href="Authors/Alec Radford.html" class="internal-link" target="_self" rel="noopener nofollow">Alec Radford</a>, <a data-href="Matthew Knight" href="Authors/Matthew Knight.html" class="internal-link" target="_self" rel="noopener nofollow">Matthew Knight</a>, <a data-href="Miles Brundage" href="Authors/Miles Brundage.html" class="internal-link" target="_self" rel="noopener nofollow">Miles Brundage</a>, <a data-href="Mira Murati" href="Authors/Mira Murati.html" class="internal-link" target="_self" rel="noopener nofollow">Mira Murati</a>, <a data-href="Katie Mayer" href="Authors/Katie Mayer.html" class="internal-link" target="_self" rel="noopener nofollow">Katie Mayer</a>, <a data-href="Peter Welinder" href="Authors/Peter Welinder.html" class="internal-link" target="_self" rel="noopener nofollow">Peter Welinder</a>, <a data-href="Bob McGrew" href="Authors/Bob McGrew.html" class="internal-link" target="_self" rel="noopener nofollow">Bob McGrew</a>, <a data-href="Dario Amodei" href="Authors/Dario Amodei.html" class="internal-link" target="_self" rel="noopener nofollow">Dario Amodei</a>, <a data-href="Sam McCandlish" href="Authors/Sam McCandlish.html" class="internal-link" target="_self" rel="noopener nofollow">Sam McCandlish</a>, <a data-href="Ilya Sutskever" href="Authors/Ilya Sutskever.html" class="internal-link" target="_self" rel="noopener nofollow">Ilya Sutskever</a>, <a data-href="Wojciech Zaremba" href="Authors/Wojciech Zaremba.html" class="internal-link" target="_self" rel="noopener nofollow">Wojciech Zaremba</a><br><br>We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics. <br><br><a data-href="HumanEval" href="Benchmarks/HumanEval.html" class="internal-link" target="_self" rel="noopener nofollow">HumanEval</a>]]></description><link>Papers/Evaluating Large Language Models Trained on Code.html</link><guid isPermaLink="false">Papers/Evaluating Large Language Models Trained on Code.md</guid><pubDate>Sun, 03 Nov 2024 18:36:46 GMT</pubDate></item><item><title><![CDATA[GLUE- A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/1804.07461" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1804.07461" target="_blank">Link</a><br><br><a data-href="Alex Wang" href="Authors/Alex Wang.html" class="internal-link" target="_self" rel="noopener nofollow">Alex Wang</a>, <a data-href="Amanpreet Singh" href="Authors/Amanpreet Singh.html" class="internal-link" target="_self" rel="noopener nofollow">Amanpreet Singh</a>, <a data-href="Julian Michael" href="Authors/Julian Michael.html" class="internal-link" target="_self" rel="noopener nofollow">Julian Michael</a>, <a data-href="Felix Hill" href="Authors/Felix Hill.html" class="internal-link" target="_self" rel="noopener nofollow">Felix Hill</a>, <a data-href="Omer Levy" href="Authors/Omer Levy.html" class="internal-link" target="_self" rel="noopener nofollow">Omer Levy</a>, <a data-href="Samuel R. Bowman" href="Authors/Samuel R. Bowman.html" class="internal-link" target="_self" rel="noopener nofollow">Samuel R. Bowman</a><br><br>For natural language understanding (NLU) technology to be maximally useful, both practically and as a scientific object of study, it must be general: it must be able to process language in a way that is not exclusively tailored to any one specific task or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation benchmark (GLUE), a tool for evaluating and analyzing the performance of models across a diverse range of existing NLU tasks. GLUE is model-agnostic, but it incentivizes sharing knowledge across tasks because certain tasks have very limited training data. We further provide a hand-crafted diagnostic test suite that enables detailed linguistic analysis of NLU models. We evaluate baselines based on current methods for multi-task and transfer learning and find that they do not immediately give substantial improvements over the aggregate performance of training a separate model per task, indicating room for improvement in developing general and robust NLU systems. <br><br><a data-href="GLUE (General Language Understanding Evaluation)" href="Benchmarks/GLUE (General Language Understanding Evaluation).html" class="internal-link" target="_self" rel="noopener nofollow">GLUE (General Language Understanding Evaluation)</a>]]></description><link>Papers/GLUE- A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding.html</link><guid isPermaLink="false">Papers/GLUE- A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding.md</guid><pubDate>Sun, 03 Nov 2024 18:41:15 GMT</pubDate></item><item><title><![CDATA[HellaSwag- Can a Machine Really Finish Your Sentence?]]></title><description><![CDATA[ 
 <br><a rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1905.07830" target="_blank">https://arxiv.org/abs/1905.07830</a><br><br><a data-href="Rowan Zellers" href="Authors/Rowan Zellers.html" class="internal-link" target="_self" rel="noopener nofollow">Rowan Zellers</a>, <a data-href="Ari Holtzman" href="Authors/Ari Holtzman.html" class="internal-link" target="_self" rel="noopener nofollow">Ari Holtzman</a>, <a data-href="Yonatan Bisk" href="Authors/Yonatan Bisk.html" class="internal-link" target="_self" rel="noopener nofollow">Yonatan Bisk</a>, <a data-href="Ali Farhadi" href="Authors/Ali Farhadi.html" class="internal-link" target="_self" rel="noopener nofollow">Ali Farhadi</a>, <a data-href="Yejin Choi" href="Authors/Yejin Choi.html" class="internal-link" target="_self" rel="noopener nofollow">Yejin Choi</a><br><br>Recent work by Zellers et al. (2018) introduced a new task of commonsense natural language inference: given an event description such as "A woman sits at a piano," a machine must select the most likely followup: "She sets her fingers on the keys." With the introduction of BERT, near human-level performance was reached. Does this mean that machines can perform human level commonsense inference?<br>
In this paper, we show that commonsense inference still proves difficult for even state-of-the-art models, by presenting HellaSwag, a new challenge dataset. Though its questions are trivial for humans (&gt;95% accuracy), state-of-the-art models struggle (&lt;48%). We achieve this via Adversarial Filtering (AF), a data collection paradigm wherein a series of discriminators iteratively select an adversarial set of machine-generated wrong answers. AF proves to be surprisingly robust. The key insight is to scale up the length and complexity of the dataset examples towards a critical 'Goldilocks' zone wherein generated text is ridiculous to humans, yet often misclassified by state-of-the-art models.<br>
Our construction of HellaSwag, and its resulting difficulty, sheds light on the inner workings of deep pretrained models. More broadly, it suggests a new path forward for NLP research, in which benchmarks co-evolve with the evolving state-of-the-art in an adversarial way, so as to present ever-harder challenges. <br><br><a data-href="HellaSwag (Harder Endings, Longer contexts and Low-shot Activities for Situations With Adversarial Generations)" href="Benchmarks/HellaSwag (Harder Endings, Longer contexts and Low-shot Activities for Situations With Adversarial Generations).html" class="internal-link" target="_self" rel="noopener nofollow">HellaSwag (Harder Endings, Longer contexts and Low-shot Activities for Situations With Adversarial Generations)</a>]]></description><link>Papers/HellaSwag- Can a Machine Really Finish Your Sentence/HellaSwag- Can a Machine Really Finish Your Sentence.html</link><guid isPermaLink="false">Papers/HellaSwag- Can a Machine Really Finish Your Sentence?.md</guid><pubDate>Sun, 03 Nov 2024 18:41:37 GMT</pubDate></item><item><title><![CDATA[Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2306.05685" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/2306.05685" target="_blank">Link</a><br><br><a data-href="Lianmin Zheng" href="Authors/Lianmin Zheng.html" class="internal-link" target="_self" rel="noopener nofollow">Lianmin Zheng</a>, <a data-href="Wei-Lin Chiang" href="Authors/Wei-Lin Chiang.html" class="internal-link" target="_self" rel="noopener nofollow">Wei-Lin Chiang</a>, <a data-href="Ying Sheng" href="Authors/Ying Sheng.html" class="internal-link" target="_self" rel="noopener nofollow">Ying Sheng</a>, <a data-href="Siyuan Zhuang" href="Authors/Siyuan Zhuang.html" class="internal-link" target="_self" rel="noopener nofollow">Siyuan Zhuang</a>, <a data-href="Zhanghao Wu" href="Authors/Zhanghao Wu.html" class="internal-link" target="_self" rel="noopener nofollow">Zhanghao Wu</a>, <a data-href="Yonghao Zhuang" href="Authors/Yonghao Zhuang.html" class="internal-link" target="_self" rel="noopener nofollow">Yonghao Zhuang</a>, <a data-href="Zi Lin" href="Authors/Zi Lin.html" class="internal-link" target="_self" rel="noopener nofollow">Zi Lin</a>, <a data-href="Zhuohan Li" href="Authors/Zhuohan Li.html" class="internal-link" target="_self" rel="noopener nofollow">Zhuohan Li</a>, <a data-href="Dacheng Li" href="Authors/Dacheng Li.html" class="internal-link" target="_self" rel="noopener nofollow">Dacheng Li</a>, <a data-href="Eric P. Xing" href="Authors/Eric P. Xing.html" class="internal-link" target="_self" rel="noopener nofollow">Eric P. Xing</a>, <a data-href="Hao Zhang" href="Authors/Hao Zhang.html" class="internal-link" target="_self" rel="noopener nofollow">Hao Zhang</a>, <a data-href="Joseph E. Gonzalez" href="Authors/Joseph E. Gonzalez.html" class="internal-link" target="_self" rel="noopener nofollow">Joseph E. Gonzalez</a>, <a data-href="Ion Stoica" href="Authors/Ion Stoica.html" class="internal-link" target="_self" rel="noopener nofollow">Ion Stoica</a><br><br>Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at this https URL. <br><br><a data-href="MT Bench" href="Benchmarks/MT Bench.html" class="internal-link" target="_self" rel="noopener nofollow">MT Bench</a>]]></description><link>Papers/Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena.html</link><guid isPermaLink="false">Papers/Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena.md</guid><pubDate>Sun, 03 Nov 2024 18:42:10 GMT</pubDate></item><item><title><![CDATA[Measuring Massive Multitask Language Understanding]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2009.03300" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/2009.03300" target="_blank">Link</a><br><br><a data-href="Dan Hendrycks" href="Authors/Dan Hendrycks.html" class="internal-link" target="_self" rel="noopener nofollow">Dan Hendrycks</a>, <a data-href="Collin Burns" href="Authors/Collin Burns.html" class="internal-link" target="_self" rel="noopener nofollow">Collin Burns</a>, <a data-href="Steven Basart" href="Authors/Steven Basart.html" class="internal-link" target="_self" rel="noopener nofollow">Steven Basart</a>, <a data-href="Andy Zou" href="Authors/Andy Zou.html" class="internal-link" target="_self" rel="noopener nofollow">Andy Zou</a>, <a data-href="Mantas Mazeika" href="Authors/Mantas Mazeika.html" class="internal-link" target="_self" rel="noopener nofollow">Mantas Mazeika</a>, <a data-href="Dawn Song" href="Authors/Dawn Song.html" class="internal-link" target="_self" rel="noopener nofollow">Dawn Song</a>, <a data-href="Jacob Steinhardt" href="Authors/Jacob Steinhardt.html" class="internal-link" target="_self" rel="noopener nofollow">Jacob Steinhardt</a><br><br>We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings. <br><br><a data-href="MMLU (Massive Multitask Language Understanding)" href="Benchmarks/MMLU (Massive Multitask Language Understanding).html" class="internal-link" target="_self" rel="noopener nofollow">MMLU (Massive Multitask Language Understanding)</a>]]></description><link>Papers/Measuring Massive Multitask Language Understanding.html</link><guid isPermaLink="false">Papers/Measuring Massive Multitask Language Understanding.md</guid><pubDate>Sun, 03 Nov 2024 18:42:52 GMT</pubDate></item><item><title><![CDATA[Program Synthesis with Large Language Models]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2108.07732" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/2108.07732" target="_blank">Link</a><br><br><a data-href="Jacob Austin" href="Authors/Jacob Austin.html" class="internal-link" target="_self" rel="noopener nofollow">Jacob Austin</a>, <a data-href="Augustus Odena" href="Authors/Augustus Odena.html" class="internal-link" target="_self" rel="noopener nofollow">Augustus Odena</a>, <a data-href="Maxwell Nye" href="Authors/Maxwell Nye.html" class="internal-link" target="_self" rel="noopener nofollow">Maxwell Nye</a>, <a data-href="Maarten Bosma" href="Authors/Maarten Bosma.html" class="internal-link" target="_self" rel="noopener nofollow">Maarten Bosma</a>, <a data-href="Henryk Michalewski" href="Authors/Henryk Michalewski.html" class="internal-link" target="_self" rel="noopener nofollow">Henryk Michalewski</a>, <a data-href="David Dohan" href="Authors/David Dohan.html" class="internal-link" target="_self" rel="noopener nofollow">David Dohan</a>, <a data-href="Ellen Jiang" href="Authors/Ellen Jiang.html" class="internal-link" target="_self" rel="noopener nofollow">Ellen Jiang</a>, <a data-href="Carrie Cai" href="Authors/Carrie Cai.html" class="internal-link" target="_self" rel="noopener nofollow">Carrie Cai</a>, <a data-href="Michael Terry" href="Authors/Michael Terry.html" class="internal-link" target="_self" rel="noopener nofollow">Michael Terry</a>, <a data-href="Quoc Le, Charles Sutton" href="Authors/Quoc Le, Charles Sutton.html" class="internal-link" target="_self" rel="noopener nofollow">Quoc Le, Charles Sutton</a><br><br>This paper explores the limits of the current generation of large language models for program synthesis in general purpose programming languages. We evaluate a collection of such models (with between 244M and 137B parameters) on two new benchmarks, MBPP and MathQA-Python, in both the few-shot and fine-tuning regimes. Our benchmarks are designed to measure the ability of these models to synthesize short Python programs from natural language descriptions. The Mostly Basic Programming Problems (MBPP) dataset contains 974 programming tasks, designed to be solvable by entry-level programmers. The MathQA-Python dataset, a Python version of the MathQA benchmark, contains 23914 problems that evaluate the ability of the models to synthesize code from more complex text. On both datasets, we find that synthesis performance scales log-linearly with model size. Our largest models, even without finetuning on a code dataset, can synthesize solutions to 59.6 percent of the problems from MBPP using few-shot learning with a well-designed prompt. Fine-tuning on a held-out portion of the dataset improves performance by about 10 percentage points across most model sizes. On the MathQA-Python dataset, the largest fine-tuned model achieves 83.8 percent accuracy. Going further, we study the model's ability to engage in dialog about code, incorporating human feedback to improve its solutions. We find that natural language feedback from a human halves the error rate compared to the model's initial prediction. Additionally, we conduct an error analysis to shed light on where these models fall short and what types of programs are most difficult to generate. Finally, we explore the semantic grounding of these models by fine-tuning them to predict the results of program execution. We find that even our best models are generally unable to predict the output of a program given a specific input. <br><br><a data-href="MBPP (Mostly Basic Programming Problems)" href="Benchmarks/MBPP (Mostly Basic Programming Problems).html" class="internal-link" target="_self" rel="noopener nofollow">MBPP (Mostly Basic Programming Problems)</a>]]></description><link>Papers/Program Synthesis with Large Language Models.html</link><guid isPermaLink="false">Papers/Program Synthesis with Large Language Models.md</guid><pubDate>Sun, 03 Nov 2024 18:43:13 GMT</pubDate></item><item><title><![CDATA[SuperGLUE- A Stickier Benchmark for General-Purpose Language Understanding Systems]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/1905.00537" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1905.00537" target="_blank">Link</a><br><br><a data-href="Alex Wang" href="Authors/Alex Wang.html" class="internal-link" target="_self" rel="noopener nofollow">Alex Wang</a>, <a data-href="Yada Pruksachatkun" href="Authors/Yada Pruksachatkun.html" class="internal-link" target="_self" rel="noopener nofollow">Yada Pruksachatkun</a>, <a data-href="Nikita Nangia" href="Authors/Nikita Nangia.html" class="internal-link" target="_self" rel="noopener nofollow">Nikita Nangia</a>, <a data-href="Amanpreet Singh" href="Authors/Amanpreet Singh.html" class="internal-link" target="_self" rel="noopener nofollow">Amanpreet Singh</a>, <a data-href="Julian Michael" href="Authors/Julian Michael.html" class="internal-link" target="_self" rel="noopener nofollow">Julian Michael</a>, <a data-href="Felix Hill" href="Authors/Felix Hill.html" class="internal-link" target="_self" rel="noopener nofollow">Felix Hill</a>, <a data-href="Omer Levy" href="Authors/Omer Levy.html" class="internal-link" target="_self" rel="noopener nofollow">Omer Levy</a>, <a data-href="Samuel R. Bowman" href="Authors/Samuel R. Bowman.html" class="internal-link" target="_self" rel="noopener nofollow">Samuel R. Bowman</a><br><br>In the last year, new models and methods for pretraining and transfer learning have driven striking performance improvements across a range of language understanding tasks. The GLUE benchmark, introduced a little over one year ago, offers a single-number metric that summarizes progress on a diverse set of such tasks, but performance on the benchmark has recently surpassed the level of non-expert humans, suggesting limited headroom for further research. In this paper we present SuperGLUE, a new benchmark styled after GLUE with a new set of more difficult language understanding tasks, a software toolkit, and a public leaderboard. SuperGLUE is available at this http URL. <br><br><a data-href="SuperGLUE" href="Benchmarks/SuperGLUE.html" class="internal-link" target="_self" rel="noopener nofollow">SuperGLUE</a>]]></description><link>Papers/SuperGLUE- A Stickier Benchmark for General-Purpose Language Understanding Systems.html</link><guid isPermaLink="false">Papers/SuperGLUE- A Stickier Benchmark for General-Purpose Language Understanding Systems.md</guid><pubDate>Sun, 03 Nov 2024 18:43:57 GMT</pubDate></item><item><title><![CDATA[Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge]]></title><description><![CDATA[ 
 <br><a rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1803.05457" target="_blank">https://arxiv.org/abs/1803.05457</a><br><br><a data-href="Peter Clark" href="Authors/Peter Clark.html" class="internal-link" target="_self" rel="noopener nofollow">Peter Clark</a>, <a data-href="Isaac Cowhey" href="Authors/Isaac Cowhey.html" class="internal-link" target="_self" rel="noopener nofollow">Isaac Cowhey</a>, <a data-href="Oren Etzioni" href="Authors/Oren Etzioni.html" class="internal-link" target="_self" rel="noopener nofollow">Oren Etzioni</a>, <a data-href="Tushar Khot" href="Authors/Tushar Khot.html" class="internal-link" target="_self" rel="noopener nofollow">Tushar Khot</a>, <a data-href="Ashish Sabharwal" href="Authors/Ashish Sabharwal.html" class="internal-link" target="_self" rel="noopener nofollow">Ashish Sabharwal</a>, <a data-href="Carissa Schoenick" href="Authors/Carissa Schoenick.html" class="internal-link" target="_self" rel="noopener nofollow">Carissa Schoenick</a>, <a data-href="Oyvind Tafjord" href="Authors/Oyvind Tafjord.html" class="internal-link" target="_self" rel="noopener nofollow">Oyvind Tafjord</a><br><br>We present a new question set, text corpus, and baselines assembled to encourage AI research in advanced question answering. Together, these constitute the AI2 Reasoning Challenge (ARC), which requires far more powerful knowledge and reasoning than previous challenges such as SQuAD or SNLI. The ARC question set is partitioned into a Challenge Set and an Easy Set, where the Challenge Set contains only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurence algorithm. The dataset contains only natural, grade-school science questions (authored for human tests), and is the largest public-domain set of this kind (7,787 questions). We test several baselines on the Challenge Set, including leading neural models from the SQuAD and SNLI tasks, and find that none are able to significantly outperform a random baseline, reflecting the difficult nature of this task. We are also releasing the ARC Corpus, a corpus of 14M science sentences relevant to the task, and implementations of the three neural baseline models tested. Can your model perform better? We pose ARC as a challenge to the community. <br><br><a data-href="AI2 Reasoning Challenge (ARC)" href="Benchmarks/AI2 Reasoning Challenge (ARC).html" class="internal-link" target="_self" rel="noopener nofollow">AI2 Reasoning Challenge (ARC)</a>]]></description><link>Papers/Think you have Solved Question Answering/Think you have Solved Question Answering.html</link><guid isPermaLink="false">Papers/Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge.md</guid><pubDate>Sun, 03 Nov 2024 18:44:47 GMT</pubDate></item><item><title><![CDATA[Towards Ecologically Valid Research on Language User Interfaces]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2007.14435" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/2007.14435" target="_blank">Link</a><br><br><a data-href="Harm de Vries" href="Authors/Harm de Vries.html" class="internal-link" target="_self" rel="noopener nofollow">Harm de Vries</a>, <a data-href="Dzmitry Bahdanau" href="Authors/Dzmitry Bahdanau.html" class="internal-link" target="_self" rel="noopener nofollow">Dzmitry Bahdanau</a>, <a data-href="Christopher Manning" href="Authors/Christopher Manning.html" class="internal-link" target="_self" rel="noopener nofollow">Christopher Manning</a><br><br>Language User Interfaces (LUIs) could improve human-machine interaction for a wide variety of tasks, such as playing music, getting insights from databases, or instructing domestic robots. In contrast to traditional hand-crafted approaches, recent work attempts to build LUIs in a data-driven way using modern deep learning methods. To satisfy the data needs of such learning algorithms, researchers have constructed benchmarks that emphasize the quantity of collected data at the cost of its naturalness and relevance to real-world LUI use cases. As a consequence, research findings on such benchmarks might not be relevant for developing practical LUIs. The goal of this paper is to bootstrap the discussion around this issue, which we refer to as the benchmarks' low ecological validity. To this end, we describe what we deem an ideal methodology for machine learning research on LUIs and categorize five common ways in which recent benchmarks deviate from it. We give concrete examples of the five kinds of deviations and their consequences. Lastly, we offer a number of recommendations as to how to increase the ecological validity of machine learning research on LUIs.<br><br><a data-href="Ecological Validity" href="Concepts/Ecological Validity.html" class="internal-link" target="_self" rel="noopener nofollow">Ecological Validity</a> ]]></description><link>Papers/Towards Ecologically Valid Research on Language User Interfaces.html</link><guid isPermaLink="false">Papers/Towards Ecologically Valid Research on Language User Interfaces.md</guid><pubDate>Sun, 03 Nov 2024 20:25:40 GMT</pubDate></item><item><title><![CDATA[Training Verifiers to Solve Math Word Problems]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2110.14168" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/2110.14168" target="_blank">Link</a><br><br><a data-href="Karl Cobbe" href="Authors/Karl Cobbe.html" class="internal-link" target="_self" rel="noopener nofollow">Karl Cobbe</a>, <a data-href="Vineet Kosaraju" href="Authors/Vineet Kosaraju.html" class="internal-link" target="_self" rel="noopener nofollow">Vineet Kosaraju</a>, <a data-href="Mohammad Bavarian" href="Authors/Mohammad Bavarian.html" class="internal-link" target="_self" rel="noopener nofollow">Mohammad Bavarian</a>, <a data-href="Mark Chen" href="Authors/Mark Chen.html" class="internal-link" target="_self" rel="noopener nofollow">Mark Chen</a>, <a data-href="Heewoo Jun" href="Authors/Heewoo Jun.html" class="internal-link" target="_self" rel="noopener nofollow">Heewoo Jun</a>, <a data-href="Lukasz Kaiser" href="Authors/Lukasz Kaiser.html" class="internal-link" target="_self" rel="noopener nofollow">Lukasz Kaiser</a>, <a data-href="Matthias Plappert" href="Authors/Matthias Plappert.html" class="internal-link" target="_self" rel="noopener nofollow">Matthias Plappert</a>, <a data-href="Jerry Tworek" href="Authors/Jerry Tworek.html" class="internal-link" target="_self" rel="noopener nofollow">Jerry Tworek</a>, <a data-href="Jacob Hilton" href="Authors/Jacob Hilton.html" class="internal-link" target="_self" rel="noopener nofollow">Jacob Hilton</a>, <a data-href="Reiichiro Nakano" href="Authors/Reiichiro Nakano.html" class="internal-link" target="_self" rel="noopener nofollow">Reiichiro Nakano</a>, <a data-href="Christopher Hesse" href="Authors/Christopher Hesse.html" class="internal-link" target="_self" rel="noopener nofollow">Christopher Hesse</a>, <a data-href="John Schulman" href="Authors/John Schulman.html" class="internal-link" target="_self" rel="noopener nofollow">John Schulman</a><br><br>State-of-the-art language models can match human performance on many tasks, but they still struggle to robustly perform multi-step mathematical reasoning. To diagnose the failures of current models and support research, we introduce GSM8K, a dataset of 8.5K high quality linguistically diverse grade school math word problems. We find that even the largest transformer models fail to achieve high test performance, despite the conceptual simplicity of this problem distribution. To increase performance, we propose training verifiers to judge the correctness of model completions. At test time, we generate many candidate solutions and select the one ranked highest by the verifier. We demonstrate that verification significantly improves performance on GSM8K, and we provide strong empirical evidence that verification scales more effectively with increased data than a finetuning baseline. <br><br><a data-href="GSM8K (Grade School Math 8K)" href="Benchmarks/GSM8K (Grade School Math 8K).html" class="internal-link" target="_self" rel="noopener nofollow">GSM8K (Grade School Math 8K)</a>]]></description><link>Papers/Training Verifiers to Solve Math Word Problems.html</link><guid isPermaLink="false">Papers/Training Verifiers to Solve Math Word Problems.md</guid><pubDate>Sun, 03 Nov 2024 18:45:01 GMT</pubDate></item><item><title><![CDATA[TruthfulQA- Measuring How Models Mimic Human Falsehoods]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2109.07958" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/2109.07958" target="_blank">Link</a><br><br><a data-href="Stephanie Lin" href="Authors/Stephanie Lin.html" class="internal-link" target="_self" rel="noopener nofollow">Stephanie Lin</a>, <a data-href="Jacob Hilton" href="Authors/Jacob Hilton.html" class="internal-link" target="_self" rel="noopener nofollow">Jacob Hilton</a>, <a data-href="Owain Evans" href="Authors/Owain Evans.html" class="internal-link" target="_self" rel="noopener nofollow">Owain Evans</a><br><br>We propose a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. We crafted questions that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from imitating human texts. We tested GPT-3, GPT-Neo/J, GPT-2 and a T5-based model. The best model was truthful on 58% of questions, while human performance was 94%. Models generated many false answers that mimic popular misconceptions and have the potential to deceive humans. The largest models were generally the least truthful. This contrasts with other NLP tasks, where performance improves with model size. However, this result is expected if false answers are learned from the training distribution. We suggest that scaling up models alone is less promising for improving truthfulness than fine-tuning using training objectives other than imitation of text from the web.<br><br><a data-href="TruthfulQA" href="Benchmarks/TruthfulQA.html" class="internal-link" target="_self" rel="noopener nofollow">TruthfulQA</a> ]]></description><link>Papers/TruthfulQA- Measuring How Models Mimic Human Falsehoods.html</link><guid isPermaLink="false">Papers/TruthfulQA- Measuring How Models Mimic Human Falsehoods.md</guid><pubDate>Sun, 03 Nov 2024 18:45:22 GMT</pubDate></item><item><title><![CDATA[WinoGrande- An Adversarial Winograd Schema Challenge at Scale]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/1907.10641" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1907.10641" target="_blank">Link</a><br><br>Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, Yejin Choi<br><br>The Winograd Schema Challenge (WSC) (Levesque, Davis, and Morgenstern 2011), a benchmark for commonsense reasoning, is a set of 273 expert-crafted pronoun resolution problems originally designed to be unsolvable for statistical models that rely on selectional preferences or word associations. However, recent advances in neural language models have already reached around 90% accuracy on variants of WSC. This raises an important question whether these models have truly acquired robust commonsense capabilities or whether they rely on spurious biases in the datasets that lead to an overestimation of the true capabilities of machine commonsense. To investigate this question, we introduce WinoGrande, a large-scale dataset of 44k problems, inspired by the original WSC design, but adjusted to improve both the scale and the hardness of the dataset. The key steps of the dataset construction consist of (1) a carefully designed crowdsourcing procedure, followed by (2) systematic bias reduction using a novel AfLite algorithm that generalizes human-detectable word associations to machine-detectable embedding associations. The best state-of-the-art methods on WinoGrande achieve 59.4-79.1%, which are 15-35% below human performance of 94.0%, depending on the amount of the training data allowed. Furthermore, we establish new state-of-the-art results on five related benchmarks - WSC (90.1%), DPR (93.1%), COPA (90.6%), KnowRef (85.6%), and Winogender (97.1%). These results have dual implications: on one hand, they demonstrate the effectiveness of WinoGrande when used as a resource for transfer learning. On the other hand, they raise a concern that we are likely to be overestimating the true capabilities of machine commonsense across all these benchmarks. We emphasize the importance of algorithmic bias reduction in existing and future benchmarks to mitigate such overestimation. <br><br><a data-href="Winogrande" href="Benchmarks/Winogrande.html" class="internal-link" target="_self" rel="noopener nofollow">Winogrande</a>]]></description><link>Papers/WinoGrande- An Adversarial Winograd Schema Challenge at Scale.html</link><guid isPermaLink="false">Papers/WinoGrande- An Adversarial Winograd Schema Challenge at Scale.md</guid><pubDate>Sun, 03 Nov 2024 18:46:09 GMT</pubDate></item><item><title><![CDATA[Academic Paper]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="" rel="noopener nofollow" class="external-link" href="" target="_blank">Link</a><br><a data-href="Reading List" href="Reading List.html" class="internal-link" target="_self" rel="noopener nofollow">Reading List</a><br><br><br>]]></description><link>Templates/Academic Paper.html</link><guid isPermaLink="false">Templates/Academic Paper.md</guid><pubDate>Sun, 03 Nov 2024 19:19:58 GMT</pubDate></item><item><title><![CDATA[AI - Overview of common LLM Benchmarks]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://dev.to/hmcodes/ai-an-overview-of-common-llm-benchmarks-3i7b" rel="noopener nofollow" class="external-link" href="https://dev.to/hmcodes/ai-an-overview-of-common-llm-benchmarks-3i7b" target="_blank">AI: Overview of common LLM benchmarks</a><br><br>
<br><a data-href="AI2 Reasoning Challenge (ARC)" href="Benchmarks/AI2 Reasoning Challenge (ARC).html" class="internal-link" target="_self" rel="noopener nofollow">AI2 Reasoning Challenge (ARC)</a>
<br><a data-href="HellaSwag (Harder Endings, Longer contexts and Low-shot Activities for Situations With Adversarial Generations)" href="Benchmarks/HellaSwag (Harder Endings, Longer contexts and Low-shot Activities for Situations With Adversarial Generations).html" class="internal-link" target="_self" rel="noopener nofollow">HellaSwag (Harder Endings, Longer contexts and Low-shot Activities for Situations With Adversarial Generations)</a>
<br><a data-href="MMLU (Massive Multitask Language Understanding)" href="Benchmarks/MMLU (Massive Multitask Language Understanding).html" class="internal-link" target="_self" rel="noopener nofollow">MMLU (Massive Multitask Language Understanding)</a>
<br><a data-href="GSM8K (Grade School Math 8K)" href="Benchmarks/GSM8K (Grade School Math 8K).html" class="internal-link" target="_self" rel="noopener nofollow">GSM8K (Grade School Math 8K)</a>
<br><a data-href="TruthfulQA" href="Benchmarks/TruthfulQA.html" class="internal-link" target="_self" rel="noopener nofollow">TruthfulQA</a>
<br><a data-href="Winogrande" href="Benchmarks/Winogrande.html" class="internal-link" target="_self" rel="noopener nofollow">Winogrande</a>
<br><a data-href="Chatbot Arena" href="Benchmarks/Chatbot Arena.html" class="internal-link" target="_self" rel="noopener nofollow">Chatbot Arena</a>
<br><a data-href="HumanEval" href="Benchmarks/HumanEval.html" class="internal-link" target="_self" rel="noopener nofollow">HumanEval</a> 
<br><a data-href="MBPP (Mostly Basic Programming Problems)" href="Benchmarks/MBPP (Mostly Basic Programming Problems).html" class="internal-link" target="_self" rel="noopener nofollow">MBPP (Mostly Basic Programming Problems)</a>
<br><a data-href="GLUE (General Language Understanding Evaluation)" href="Benchmarks/GLUE (General Language Understanding Evaluation).html" class="internal-link" target="_self" rel="noopener nofollow">GLUE (General Language Understanding Evaluation)</a>
]]></description><link>Webpages/AI - Overview of common LLM Benchmarks.html</link><guid isPermaLink="false">Webpages/AI - Overview of common LLM Benchmarks.md</guid><pubDate>Sat, 02 Nov 2024 18:43:56 GMT</pubDate></item><item><title><![CDATA[AI Fairness 360]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://ai-fairness-360.org/" rel="noopener nofollow" class="external-link" href="https://ai-fairness-360.org/" target="_blank">Link</a><br>From IBM]]></description><link>Webpages/AI Fairness 360.html</link><guid isPermaLink="false">Webpages/AI Fairness 360.md</guid><pubDate>Sun, 03 Nov 2024 19:43:20 GMT</pubDate></item><item><title><![CDATA[An In-depth Guide to Benchmarking LLMs]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://symbl.ai/developers/blog/an-in-depth-guide-to-benchmarking-llms/" rel="noopener nofollow" class="external-link" href="https://symbl.ai/developers/blog/an-in-depth-guide-to-benchmarking-llms/" target="_blank">Webpage</a><br>Collection of Questions or Tasks<br>
Scoring Mechanism<br>
<br><a data-href="AI2 Reasoning Challenge (ARC)" href="Benchmarks/AI2 Reasoning Challenge (ARC).html" class="internal-link" target="_self" rel="noopener nofollow">AI2 Reasoning Challenge (ARC)</a>
<br><a data-href="HellaSwag (Harder Endings, Longer contexts and Low-shot Activities for Situations With Adversarial Generations)" href="Benchmarks/HellaSwag (Harder Endings, Longer contexts and Low-shot Activities for Situations With Adversarial Generations).html" class="internal-link" target="_self" rel="noopener nofollow">HellaSwag (Harder Endings, Longer contexts and Low-shot Activities for Situations With Adversarial Generations)</a>
<br><a data-href="MMLU (Massive Multitask Language Understanding)" href="Benchmarks/MMLU (Massive Multitask Language Understanding).html" class="internal-link" target="_self" rel="noopener nofollow">MMLU (Massive Multitask Language Understanding)</a>
<br><a data-href="TruthfulQA" href="Benchmarks/TruthfulQA.html" class="internal-link" target="_self" rel="noopener nofollow">TruthfulQA</a>
<br><a data-href="Winogrande" href="Benchmarks/Winogrande.html" class="internal-link" target="_self" rel="noopener nofollow">Winogrande</a>
<br><a data-href="GSM8K (Grade School Math 8K)" href="Benchmarks/GSM8K (Grade School Math 8K).html" class="internal-link" target="_self" rel="noopener nofollow">GSM8K (Grade School Math 8K)</a>
<br><a data-href="SuperGLUE" href="Benchmarks/SuperGLUE.html" class="internal-link" target="_self" rel="noopener nofollow">SuperGLUE</a>
<br><a data-href="HumanEval" href="Benchmarks/HumanEval.html" class="internal-link" target="_self" rel="noopener nofollow">HumanEval</a>
<br><a data-href="MT Bench" href="Benchmarks/MT Bench.html" class="internal-link" target="_self" rel="noopener nofollow">MT Bench</a>
<br><br>a published list of benchmark results for each language model. The designers of each benchmark tend to maintain their own LLM leaderboards, but there are also independent leaderboards that evaluate models on a series of benchmarks for a more comprehensive assessment of their abilities.  <br><a data-tooltip-position="top" aria-label="https://huggingface.co/collections/open-llm-leaderboard/the-big-benchmarks-collection-64faca6335a7fc7d4ffe974a" rel="noopener nofollow" class="external-link" href="https://huggingface.co/collections/open-llm-leaderboard/the-big-benchmarks-collection-64faca6335a7fc7d4ffe974a" target="_blank">HuggingFace Leaderboars</a><br><br>
<br>Dataset leakage (models sometimes train on dataset by accident - oops!)
<br>As benchmarks become popular,  models can be tuned to those benchmarks (marking incentive)
<br>Measure of performance happens in a controlled environment - is it representative of reality?
<br>Performance on specific knowledge domains is unclear because most benchmarks are against general knowledge
]]></description><link>Webpages/An In-depth Guide to Benchmarking LLMs.html</link><guid isPermaLink="false">Webpages/An In-depth Guide to Benchmarking LLMs.md</guid><pubDate>Sat, 02 Nov 2024 21:55:10 GMT</pubDate></item><item><title><![CDATA[An introduction to code LLM benchmarks for software engineers]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://blog.continue.dev/an-introduction-to-code-llm-benchmarks-for-software-engineers/" rel="noopener nofollow" class="external-link" href="https://blog.continue.dev/an-introduction-to-code-llm-benchmarks-for-software-engineers/" target="_blank">Link</a>]]></description><link>Webpages/An introduction to code LLM benchmarks for software engineers.html</link><guid isPermaLink="false">Webpages/An introduction to code LLM benchmarks for software engineers.md</guid><pubDate>Sun, 03 Nov 2024 18:17:21 GMT</pubDate></item><item><title><![CDATA[Benchmarking AI]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://mlsysbook.ai/contents/benchmarking/benchmarking.html" rel="noopener nofollow" class="external-link" href="https://mlsysbook.ai/contents/benchmarking/benchmarking.html" target="_blank">Website</a><br><br>
<br>Performance assessment
<br>Resource evaluation (e.g. hardware)
<br>Validation and Verification
<br>Competitive analysis
<br>Credibility
<br>Regulation and Standardization 
<br>Successful benchmarks have community consensus<br>Benchmarking can happen at different levels of granularity,  from individual activation function performance to end-to-end application performance and user experience. <br><br>
<br>System Benchmarks (e.g. hardware, training times, etc)
<br>Model Benchmarks (e.g. "accuracy")
<br>Data Benchmarks (e.g. quality, diversity)
<br><br>
<br>Standardized Datasets
<br>Pre-defined Tasks
<br>Evaluation Metrics
<br>Baselines and Baseline Models
<br>Hardware and Software Specs
<br>Environmental Conditions (e.g. power source, background processes
<br>Reproducibility protocols (.e.g random seeds, hyper-parameters)
<br>Result Interpretation (e.g. assessment of appropriateness of metric to various real-world use cases) 
<br><br>
<br>Training Benchmarks - System oriented. Usually care about optimizating for time or compute resources
<br>Inference Benchmarks  - Model oriented. Cares about accuracy, precision, recall
<br><br>
<br>Training Time
<br>Scalability
<br>Resource Utilization
<br>Memory Consumption
<br>Energy Consumption
<br>Throughput
<br>Cost
<br>Fault Tolerance/Robustness (of training process)
<br>Reproducibility
<br><br>
<br><a data-tooltip-position="top" aria-label="https://github.com/mlcommons/training" rel="noopener nofollow" class="external-link" href="https://github.com/mlcommons/training" target="_blank">MLPerf Training Benchmark</a>
<br><a data-tooltip-position="top" aria-label="https://dawn.cs.stanford.edu/benchmark/" rel="noopener nofollow" class="external-link" href="https://dawn.cs.stanford.edu/benchmark/" target="_blank">AWNBench</a>
<br><a data-tooltip-position="top" aria-label="https://github.com/rdadolf/fathom" rel="noopener nofollow" class="external-link" href="https://github.com/rdadolf/fathom" target="_blank">Fathom</a>
<br><br>
<br>Accuracy
<br>Latency
<br>Throughput
<br>Latency-Bounded Throughput (e..g how many video frames the system can process per second (throughput) while ensuring that the subtitles are displayed with no more than a 1-second delay (latency))
<br>Energy Efficiency
<br>Memory Usage
<br><br>
<br><a data-tooltip-position="top" aria-label="https://github.com/mlcommons/inference" rel="noopener nofollow" class="external-link" href="https://github.com/mlcommons/inference" target="_blank">MLPerf Inference Benchmark</a>
<br><a data-tooltip-position="top" aria-label="https://ai-benchmark.com/" rel="noopener nofollow" class="external-link" href="https://ai-benchmark.com/" target="_blank">AI Benchmark</a>
<br><a data-tooltip-position="top" aria-label="https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html" rel="noopener nofollow" class="external-link" href="https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html" target="_blank">OpenVINO toolkit</a>:
<br><br><br>
<br><a data-tooltip-position="top" aria-label="https://www.tensorflow.org/datasets/catalog/mnist" rel="noopener nofollow" class="external-link" href="https://www.tensorflow.org/datasets/catalog/mnist" target="_blank">MNIST dataset</a>
<br><a data-tooltip-position="top" aria-label="https://www.tensorflow.org/datasets/catalog/imagenet2012" rel="noopener nofollow" class="external-link" href="https://www.tensorflow.org/datasets/catalog/imagenet2012" target="_blank">ImageNet dataset</a>
<br><a data-tooltip-position="top" aria-label="https://cocodataset.org/" rel="noopener nofollow" class="external-link" href="https://cocodataset.org/" target="_blank">Common Objects in Context (COCO) dataset</a>
<br>GPT-3 - Dataset not available
<br><br>
<br>Accuracy (and associated problems)
<br>Fairness (how does this model operate on different subgroups of the data - see why accuracy is not a good measure)

<br><a data-href="AI Fairness 360" href="Webpages/AI Fairness 360.html" class="internal-link" target="_self" rel="noopener nofollow">AI Fairness 360</a>
<br><a data-href="Tensorflow - Fairness Indicators" href="Webpages/Tensorflow - Fairness Indicators.html" class="internal-link" target="_self" rel="noopener nofollow">Tensorflow - Fairness Indicators</a>


<br>Complexity (number of parameters, floating point operations per second)
<br>Efficiency (e.g. system metrics)
<br><br>"...the emphasis shifts to curating high-quality datasets that better reflect real-world complexity, developing more informative evaluation benchmarks, and carefully considering how data is sampled, preprocessed, and augmented. The goal is to optimize model behavior by improving the data rather than just optimizing metrics on flawed datasets."<br>Data-centric AI - improve data not code for better real-world performance<br><br>
<br>Labeling Errors
<br>Noisy features
<br>Representation imbalance (over representation of certain subsets)
<br>Class imbalance (imbalanced class examples)
<br>Biases
<br><br>
<br><a data-href="DataComp" href="Webpages/DataComp.html" class="internal-link" target="_self" rel="noopener nofollow">DataComp</a>
<br><a data-href="DataPerf" href="Webpages/DataPerf.html" class="internal-link" target="_self" rel="noopener nofollow">DataPerf</a> 
]]></description><link>Webpages/Benchmarking AI.html</link><guid isPermaLink="false">Webpages/Benchmarking AI.md</guid><pubDate>Sun, 03 Nov 2024 20:57:11 GMT</pubDate></item><item><title><![CDATA[DataComp]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://www.datacomp.ai/" rel="noopener nofollow" class="external-link" href="https://www.datacomp.ai/" target="_blank">Link</a>]]></description><link>Webpages/DataComp.html</link><guid isPermaLink="false">Webpages/DataComp.md</guid><pubDate>Sun, 03 Nov 2024 20:30:43 GMT</pubDate></item><item><title><![CDATA[DataPerf]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://www.dataperf.org/" rel="noopener nofollow" class="external-link" href="https://www.dataperf.org/" target="_blank">Link</a>]]></description><link>Webpages/DataPerf.html</link><guid isPermaLink="false">Webpages/DataPerf.md</guid><pubDate>Sun, 03 Nov 2024 20:31:45 GMT</pubDate></item><item><title><![CDATA[Errors in the MMLU- The Deep Learning Benchmark is Wrong Surprisingly Often]]></title><description><![CDATA[ 
 <br>[Link](Errors in the MMLU: The Deep Learning Benchmark is Wrong Surprisingly Often)]]></description><link>Webpages/Errors in the MMLU- The Deep Learning Benchmark is Wrong Surprisingly Often.html</link><guid isPermaLink="false">Webpages/Errors in the MMLU- The Deep Learning Benchmark is Wrong Surprisingly Often.md</guid><pubDate>Sun, 03 Nov 2024 18:18:22 GMT</pubDate></item><item><title><![CDATA[NIST - AI RMF]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://www.nist.gov/itl/ai-risk-management-framework" rel="noopener nofollow" class="external-link" href="https://www.nist.gov/itl/ai-risk-management-framework" target="_blank">Landing Page</a><br>
<a data-tooltip-position="top" aria-label="https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf" rel="noopener nofollow" class="external-link" href="https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf" target="_blank">PDF</a>]]></description><link>Webpages/NIST - AI RMF.html</link><guid isPermaLink="false">Webpages/NIST - AI RMF.md</guid><pubDate>Sun, 03 Nov 2024 18:21:40 GMT</pubDate></item><item><title><![CDATA[Tensorflow - Fairness Indicators]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://www.tensorflow.org/tfx/guide/fairness_indicators" rel="noopener nofollow" class="external-link" href="https://www.tensorflow.org/tfx/guide/fairness_indicators" target="_blank">Link</a>]]></description><link>Webpages/Tensorflow - Fairness Indicators.html</link><guid isPermaLink="false">Webpages/Tensorflow - Fairness Indicators.md</guid><pubDate>Sun, 03 Nov 2024 19:43:57 GMT</pubDate></item><item><title><![CDATA[Annotated Bibliography]]></title><description><![CDATA[ 
 <br><br>Provides an executive overview of a number of common benchmarks used to compare industry models.  Follows a "Goal/Test" format that makes it easy to triage the benchmarks it covers for applicability to various tasks. <a data-tooltip-position="top" aria-label="https://dev.to/hmcodes/ai-an-overview-of-common-llm-benchmarks-3i7b" rel="noopener nofollow" class="external-link" href="https://dev.to/hmcodes/ai-an-overview-of-common-llm-benchmarks-3i7b" target="_blank">Link</a> <br><br>Provides links to a number of common benchmarks used to compare industry models. Gives a paragraph on each model (often with key information on the quantitative evaluation of the benchmark). Provides a generalized Pros/Cons assessment of each data set. <a data-tooltip-position="top" aria-label="https://symbl.ai/developers/blog/an-in-depth-guide-to-benchmarking-llms/" rel="noopener nofollow" class="external-link" href="https://symbl.ai/developers/blog/an-in-depth-guide-to-benchmarking-llms/" target="_blank">Link</a><br><br>Extensive overview of various types of benchmarks for evaluation of AI across System, Model &amp; Data dimensions. Authors have a clear preference for raising the visibility of System metrics (e.g. memory consumption, training time, etc) <a data-tooltip-position="top" aria-label="https://mlsysbook.ai/contents/benchmarking/benchmarking.html" rel="noopener nofollow" class="external-link" href="https://mlsysbook.ai/contents/benchmarking/benchmarking.html" target="_blank">Link</a>]]></description><link>Annotated Bibliography.html</link><guid isPermaLink="false">Annotated Bibliography.md</guid><pubDate>Sun, 03 Nov 2024 21:12:16 GMT</pubDate></item><item><title><![CDATA[Reading List]]></title><description><![CDATA[ 
 <br><br>
<br><a data-href="AI - Overview of common LLM Benchmarks" href="Webpages/AI - Overview of common LLM Benchmarks.html" class="internal-link" target="_self" rel="noopener nofollow">AI - Overview of common LLM Benchmarks</a>
<br><a data-href="An In-depth Guide to Benchmarking LLMs" href="Webpages/An In-depth Guide to Benchmarking LLMs.html" class="internal-link" target="_self" rel="noopener nofollow">An In-depth Guide to Benchmarking LLMs</a>
<br><a data-href="Benchmarking AI" href="Webpages/Benchmarking AI.html" class="internal-link" target="_self" rel="noopener nofollow">Benchmarking AI</a>
<br><a data-href="AI Fairness 360" href="Webpages/AI Fairness 360.html" class="internal-link" target="_self" rel="noopener nofollow">AI Fairness 360</a>
<br><a data-href="Tensorflow - Fairness Indicators" href="Webpages/Tensorflow - Fairness Indicators.html" class="internal-link" target="_self" rel="noopener nofollow">Tensorflow - Fairness Indicators</a>
<br><a data-href="DataComp" href="Webpages/DataComp.html" class="internal-link" target="_self" rel="noopener nofollow">DataComp</a>
<br><a data-href="DataPerf" href="Webpages/DataPerf.html" class="internal-link" target="_self" rel="noopener nofollow">DataPerf</a>
<br><a data-href="An introduction to code LLM benchmarks for software engineers" href="Webpages/An introduction to code LLM benchmarks for software engineers.html" class="internal-link" target="_self" rel="noopener nofollow">An introduction to code LLM benchmarks for software engineers</a>
<br><a data-href="Chain of Thought" href="Concepts/Chain of Thought.html" class="internal-link" target="_self" rel="noopener nofollow">Chain of Thought</a>
<br><a data-href="Errors in the MMLU- The Deep Learning Benchmark is Wrong Surprisingly Often" href="Webpages/Errors in the MMLU- The Deep Learning Benchmark is Wrong Surprisingly Often.html" class="internal-link" target="_self" rel="noopener nofollow">Errors in the MMLU- The Deep Learning Benchmark is Wrong Surprisingly Often</a>
<br><br>
<br><a data-href="Chatbot Arena- An Open Platform for Evaluating LLMs by Human Preference" href="Papers/Chatbot Arena- An Open Platform for Evaluating LLMs by Human Preference.html" class="internal-link" target="_self" rel="noopener nofollow">Chatbot Arena- An Open Platform for Evaluating LLMs by Human Preference</a>
<br><a data-href="Evaluating Large Language Models Trained on Code" href="Papers/Evaluating Large Language Models Trained on Code.html" class="internal-link" target="_self" rel="noopener nofollow">Evaluating Large Language Models Trained on Code</a>
<br><a data-href="GLUE- A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding" href="Papers/GLUE- A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding.html" class="internal-link" target="_self" rel="noopener nofollow">GLUE- A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding</a>
<br><a data-href="HellaSwag- Can a Machine Really Finish Your Sentence?" href="Papers/HellaSwag- Can a Machine Really Finish Your Sentence" class="internal-link" target="_self" rel="noopener nofollow">HellaSwag- Can a Machine Really Finish Your Sentence?</a>
<br><a data-href="Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena" href="Papers/Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena.html" class="internal-link" target="_self" rel="noopener nofollow">Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena</a>
<br><a data-href="Measuring Massive Multitask Language Understanding" href="Papers/Measuring Massive Multitask Language Understanding.html" class="internal-link" target="_self" rel="noopener nofollow">Measuring Massive Multitask Language Understanding</a>
<br><a data-href="Program Synthesis with Large Language Models" href="Papers/Program Synthesis with Large Language Models.html" class="internal-link" target="_self" rel="noopener nofollow">Program Synthesis with Large Language Models</a>
<br><a data-href="SuperGLUE- A Stickier Benchmark for General-Purpose Language Understanding Systems" href="Papers/SuperGLUE- A Stickier Benchmark for General-Purpose Language Understanding Systems.html" class="internal-link" target="_self" rel="noopener nofollow">SuperGLUE- A Stickier Benchmark for General-Purpose Language Understanding Systems</a>
<br><a data-href="Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge" href="Papers/Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge" class="internal-link" target="_self" rel="noopener nofollow">Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge</a>
<br><a data-href="Training Verifiers to Solve Math Word Problems" href="Papers/Training Verifiers to Solve Math Word Problems.html" class="internal-link" target="_self" rel="noopener nofollow">Training Verifiers to Solve Math Word Problems</a>
<br><a data-href="TruthfulQA- Measuring How Models Mimic Human Falsehoods" href="Papers/TruthfulQA- Measuring How Models Mimic Human Falsehoods.html" class="internal-link" target="_self" rel="noopener nofollow">TruthfulQA- Measuring How Models Mimic Human Falsehoods</a>
<br><a data-href="WinoGrande- An Adversarial Winograd Schema Challenge at Scale" href="Papers/WinoGrande- An Adversarial Winograd Schema Challenge at Scale.html" class="internal-link" target="_self" rel="noopener nofollow">WinoGrande- An Adversarial Winograd Schema Challenge at Scale</a>
<br><br>
<br><a data-href="NIST - AI RMF" href="Webpages/NIST - AI RMF.html" class="internal-link" target="_self" rel="noopener nofollow">NIST - AI RMF</a>
<br><a data-href="Towards Ecologically Valid Research on Language User Interfaces" href="Papers/Towards Ecologically Valid Research on Language User Interfaces.html" class="internal-link" target="_self" rel="noopener nofollow">Towards Ecologically Valid Research on Language User Interfaces</a>
]]></description><link>Reading List.html</link><guid isPermaLink="false">Reading List.md</guid><pubDate>Sun, 03 Nov 2024 20:31:53 GMT</pubDate></item></channel></rss>